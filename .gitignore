"""
AuditTOOL7000.py  -  Solidity Smart Contract Security Auditor
=============================================================
Single file. Run from PowerShell / bash:

  # Install dependencies (once):
  pip install rich python-docx py-solc-x

  # Audit a single file:
  python AuditTOOL7000.py contracts/MyToken.sol

  # Audit a Foundry / Hardhat PROJECT DIRECTORY (auto-detected):
  python AuditTOOL7000.py /path/to/my-foundry-project
  python AuditTOOL7000.py /path/to/my-hardhat-project

  # Selected analyzers + Word report:
  python AuditTOOL7000.py MyToken.sol --slither --mythril --doc

  # Interactive mode (drag & drop in browser):
  python AuditTOOL7000.py

  # All flags:
  python AuditTOOL7000.py --help

Improvements over v6000:
  • Foundry project support  (foundry.toml detection, forge build, forge test)
  • Hardhat project support  (hardhat.config.js/ts detection, npx hardhat compile/test)
  • Smart project detection  (auto-detect single file vs Foundry vs Hardhat)
  • Slither/Mythril/Echidna/Medusa/Halmos run natively on project root with deps
  • Static analysis upgraded: strips comments before regex → fewer false positives,
    regex findings are tagged Info/Low (Slither is the real static engine)
  • Foundry test results parsed and surfaced as findings
"""

# ─────────────────────────────────────────────
#  STANDARD LIBRARY
# ─────────────────────────────────────────────
import argparse
import hashlib
import http.server
import json
import logging
import os
import re
import shutil
import subprocess
import sys
import tempfile
import threading
import time
import webbrowser
from docx.enum.text import WD_ALIGN_PARAGRAPH
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from typing import Optional

# ─────────────────────────────────────────────
#  EXTERNAL DEPENDENCIES
#  pip install rich python-docx
# ─────────────────────────────────────────────
try:
    from rich.console import Console
    from rich.table   import Table
    from rich.panel   import Panel
    from rich         import box as rich_box
    HAS_RICH = True
except ImportError:
    HAS_RICH = False
    print("[WARNING] 'rich' is not installed. Run: pip install rich")

try:
    from docx                        import Document as DocxDocument
    from docx.shared                 import Pt, RGBColor, Inches, Cm
    from docx.enum.text              import WD_ALIGN_PARAGRAPH
    from docx.enum.table             import WD_TABLE_ALIGNMENT
    from docx.oxml.ns                import qn
    from docx.oxml                   import OxmlElement
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False
    print("[WARNING] 'python-docx' is not installed. Run: pip install python-docx")

# ─────────────────────────────────────────────
#  OPTIONAL: py-solc-x for AST semantic analysis
#  pip install py-solc-x
# ─────────────────────────────────────────────
try:
    import solcx
    HAS_SOLCX = True
except ImportError:
    HAS_SOLCX = False


# ─────────────────────────────────────────────────────────────────────────────
#  LOGGING
# ─────────────────────────────────────────────────────────────────────────────

logging.basicConfig(
    filename="audit.log",
    level=logging.INFO,
    format="%(asctime)s  %(levelname)-8s  %(message)s",
    encoding="utf-8",
)
logger  = logging.getLogger(__name__)
console = Console() if HAS_RICH else None


def _print(msg: str, style: str = "") -> None:
    """Print to console via rich or plain print."""
    if console:
        console.print(f"[{style}]{msg}[/{style}]" if style else msg)
    else:
        print(msg)


# ─────────────────────────────────────────────────────────────────────────────
#  CONSTANTS
# ─────────────────────────────────────────────────────────────────────────────

TEMP_DIR    = tempfile.gettempdir()
# Файлы отчётов сохраняются рядом со скриптом, а не в текущей рабочей директории.
# Это предотвращает ошибку "Permission denied" при запуске из защищённых папок.
_SCRIPT_DIR  = os.path.dirname(os.path.abspath(__file__))
DOC_OUTPUT  = os.path.join(_SCRIPT_DIR, "audit_report.docx")
JSON_OUTPUT = os.path.join(_SCRIPT_DIR, "audit_report.json")

SWC_IDS: dict[str, str] = {
    "reentrancy":              "SWC-107",
    "unsafe_call":             "SWC-107",
    "deprecated_function":     "SWC-111",
    "flash_loan":              "SWC-132",
    "oracle_manipulation":     "SWC-117",
    "tx_origin":               "SWC-115",
    "missing_access_modifier": "SWC-100",
    "unsafe_math":             "SWC-101",
    "block_timestamp":         "SWC-116",
    "delegatecall":            "SWC-112",
    "assert_usage":            "SWC-110",
    "unbounded_loop":          "SWC-119",
    "hardcoded_address":       "SWC-104",
    "frontrunning":            "SWC-114",
    "assembly_storage":        "SWC-127",
    "dos_external_calls":      "SWC-113",
    "unchecked_call_returns":  "SWC-104",
    "weak_randomness":         "SWC-120",
    "unlimited_mint":                     "Custom-001",
    "proxy_issues":                       "Custom-002",
    "missing_pragma":                     "SWC-103",
    "floating_pragma":                    "SWC-103",
    "unrecognised_pragma":                "SWC-103",
    "outdated_solidity_version":          "SWC-102",
    "vulnerable_solidity_version":        "SWC-102",
    "slightly_outdated_solidity_version": "SWC-102",
    # ── Новые ──────────────────────────────────────────────────────────────
    "selfdestruct":            "SWC-106",
    "initialize_unprotected":  "Custom-003",
    "ecrecover":               "SWC-117",
    "approve_race":            "SWC-114",
    "abi_encode_packed":       "SWC-133",
    "signature_replay":        "SWC-121",
    "price_manipulation":      "Custom-004",
    "unchecked_block":         "SWC-101",
    "silent_overflow":         "SWC-101",
    "erc20_unchecked":         "SWC-104",
    "eth_transfer_old":        "SWC-134",
    "block_number_time":       "SWC-116",
    "open_receive":            "Custom-005",
    "integer_division":        "Custom-006",
    "ownership_transfer":      "Custom-007",
    "msg_value_loop":          "Custom-008",
}

# ─────────────────────────────────────────────────────────────────────────────
#  CVSS-LIKE SCORING  (base score per vulnerability type)
#  Fields: AV=AttackVector, AC=AttackComplexity, PR=PrivilegesRequired,
#          UI=UserInteraction, S=Scope, C=Confidentiality,
#          I=Integrity, A=Availability
#  Score is 0.0–10.0, rounded to 1 decimal.
#  Severity band: 0.0=None, 0.1-3.9=Low, 4.0-6.9=Medium,
#                 7.0-8.9=High, 9.0-10.0=Critical
# ─────────────────────────────────────────────────────────────────────────────

CVSS_SCORES: dict[str, dict] = {
    # type_key             : {score, vector_string}
    "reentrancy":              {"score": 9.8,  "vector": "AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H"},
    "unsafe_call":             {"score": 8.1,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H"},
    "tx_origin":               {"score": 8.8,  "vector": "AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H"},
    "flash_loan":              {"score": 9.1,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"},
    "oracle_manipulation":     {"score": 9.1,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"},
    "selfdestruct":            {"score": 9.0,  "vector": "AV:N/AC:L/PR:N/UI:N/S:C/C:N/I:H/A:H"},
    "initialize_unprotected":  {"score": 9.8,  "vector": "AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H"},
    "price_manipulation":      {"score": 9.1,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"},
    "msg_value_loop":          {"score": 9.0,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"},
    "unlimited_mint":          {"score": 9.8,  "vector": "AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H"},
    "signature_replay":        {"score": 8.1,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H"},
    "ecrecover":               {"score": 7.5,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N"},
    "delegatecall":            {"score": 8.1,  "vector": "AV:N/AC:H/PR:N/UI:N/S:C/C:H/I:H/A:H"},
    "erc20_unchecked":         {"score": 7.5,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N"},
    "silent_overflow":         {"score": 7.5,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N"},
    "unchecked_call_returns":  {"score": 7.5,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N"},
    "weak_randomness":         {"score": 7.4,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:N"},
    "proxy_issues":            {"score": 7.0,  "vector": "AV:N/AC:H/PR:L/UI:N/S:C/C:H/I:H/A:N"},
    "unsafe_math":             {"score": 6.5,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:M/A:N"},
    "unchecked_block":         {"score": 6.5,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:M/A:N"},
    "abi_encode_packed":       {"score": 6.5,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:L/I:H/A:N"},
    "approve_race":            {"score": 6.1,  "vector": "AV:N/AC:H/PR:N/UI:R/S:U/C:N/I:H/A:N"},
    "eth_transfer_old":        {"score": 5.3,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:M"},
    "ownership_transfer":      {"score": 5.3,  "vector": "AV:N/AC:L/PR:H/UI:N/S:U/C:N/I:H/A:N"},
    "frontrunning":            {"score": 5.9,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:H/A:N"},
    "block_timestamp":         {"score": 5.3,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:M/A:N"},
    "block_number_time":       {"score": 3.7,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:L/A:N"},
    "assert_usage":            {"score": 3.7,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:L"},
    "unbounded_loop":          {"score": 5.3,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:M"},
    "dos_external_calls":      {"score": 5.3,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:M"},
    "deprecated_function":     {"score": 4.3,  "vector": "AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:L/A:N"},
    "hardcoded_address":       {"score": 3.7,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:L/I:L/A:N"},
    "assembly_storage":        {"score": 5.5,  "vector": "AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N"},
    "floating_pragma":         {"score": 3.7,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:L/A:N"},
    "missing_pragma":          {"score": 5.0,  "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:L/A:N"},
    "outdated_solidity_version":         {"score": 6.5, "vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:M/A:N"},
    "vulnerable_solidity_version":       {"score": 5.3, "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:M/A:N"},
    "slightly_outdated_solidity_version":{"score": 3.7, "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:L/A:N"},
    "open_receive":            {"score": 3.1,  "vector": "AV:N/AC:H/PR:N/UI:R/S:U/C:N/I:L/A:N"},
    "integer_division":        {"score": 3.7,  "vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:L/A:N"},
}

# Default score for unknown finding types (mapped by severity band)
_CVSS_SEVERITY_DEFAULT = {
    "Critical": 9.0,
    "High":     7.5,
    "Medium":   5.0,
    "Low":      2.5,
    "Info":     0.0,
}


def compute_cvss_score(finding: dict) -> float:
    """
    Return the CVSS-like numeric score (0.0–10.0) for a finding.
    Uses the pre-defined table; falls back to severity-band default.
    """
    ftype = finding.get("type", "")
    entry = CVSS_SCORES.get(ftype)
    if entry:
        return entry["score"]
    return _CVSS_SEVERITY_DEFAULT.get(finding.get("severity", "Low"), 2.5)


def cvss_severity_band(score: float) -> str:
    """Map a CVSS numeric score to a severity band label."""
    if score >= 9.0:
        return "Critical"
    if score >= 7.0:
        return "High"
    if score >= 4.0:
        return "Medium"
    if score > 0.0:
        return "Low"
    return "Info"


def enrich_with_cvss(findings: list[dict]) -> list[dict]:
    """
    Attach cvss_score, cvss_vector, and risk_priority to every finding in-place.
    risk_priority = 1 (highest) … N (lowest), sorted by score desc then severity.

    IMPORTANT: findings from StaticAnalysis (regex) are intentionally clamped to
    Info — we never upgrade them via CVSS, because regex has high false-positive
    rate. Slither/Mythril will report the real severity independently.

    Returns the same list (mutated).
    """
    for f in findings:
        score = compute_cvss_score(f)
        f["cvss_score"]  = score
        f["cvss_vector"] = CVSS_SCORES.get(f.get("type", ""), {}).get("vector", "N/A")

        # Only upgrade severity via CVSS for non-regex tools.
        # StaticAnalysis (regex) findings stay at Info — always.
        if f.get("tool") == "StaticAnalysis":
            f["severity"] = f.get("severity", "Info")   # keep as-is (Info)
        else:
            # Override severity with the CVSS band only when stricter
            cvss_sev = cvss_severity_band(score)
            existing_order = {"Critical": 0, "High": 1, "Medium": 2, "Low": 3, "Info": 4}
            if existing_order.get(cvss_sev, 4) < existing_order.get(f.get("severity", "Low"), 4):
                f["severity"] = cvss_sev

    # Assign priority rank (1 = most dangerous)
    ranked = sorted(findings, key=lambda x: -x.get("cvss_score", 0))
    for rank, f in enumerate(ranked, 1):
        f["risk_priority"] = rank

    return findings


# ─────────────────────────────────────────────────────────────────────────────
#  AST SEMANTIC ANALYSIS  (via solcx / solc --ast-compact-json)
#  Parses the Solidity AST to find structural issues that regex cannot catch.
# ─────────────────────────────────────────────────────────────────────────────

def run_ast_analysis(contract_path: str, source: str) -> list[dict]:
    """
    Semantic analysis using the Solidity compiler's AST output.
    Requires either:
      - py-solc-x  (pip install py-solc-x) — preferred, auto-installs solc
      - solc binary in PATH  (fallback)
    Returns a list of findings in the standard finding dict format.
    """
    _print("Running AST semantic analysis...", "cyan")
    findings: list[dict] = []

    ast_json: Optional[dict] = None

    # ── Try solcx first (most reliable) ──────────────────────────────────────
    if HAS_SOLCX:
        try:
            # Detect the pragma version and install matching solc if needed
            ver_match = re.search(r"pragma\s+solidity\s+[\^~]?(\d+\.\d+\.\d+)", source)
            solc_ver  = ver_match.group(1) if ver_match else None

            if solc_ver:
                try:
                    solcx.install_solc(solc_ver, show_progress=False)
                    solcx.set_solc_version(solc_ver)
                except Exception:
                    pass  # Use whatever version is installed

            result = solcx.compile_source(
                source,
                output_values=["ast"],
                solc_version=solc_ver,
            )
            # result keys look like "<stdin>:ContractName"
            for key, val in result.items():
                if "ast" in val:
                    ast_json = val["ast"]
                    break
        except Exception as exc:
            logger.info("solcx AST compile failed: %s", exc)
            ast_json = None

    # ── Fallback: solc binary --ast-compact-json ──────────────────────────────
    if ast_json is None and shutil.which("solc"):
        try:
            code, stdout, stderr = run_tool(
                ["solc", "--ast-compact-json", contract_path], timeout=60
            )
            if code == 0 and stdout:
                # solc outputs "=== <filename> ===" then JSON blocks
                for block in re.split(r"={3,}[^=]+={3,}", stdout):
                    block = block.strip()
                    if block.startswith("{"):
                        try:
                            ast_json = json.loads(block)
                            break
                        except json.JSONDecodeError:
                            pass
        except Exception as exc:
            logger.info("solc AST binary fallback failed: %s", exc)

    if ast_json is None:
        _print(
            "AST analysis skipped — install py-solc-x: pip install py-solc-x",
            "yellow",
        )
        return []

    # ── Walk the AST and apply semantic checks ───────────────────────────────
    findings += _ast_check_state_mutability(ast_json)
    findings += _ast_check_missing_zero_address(ast_json)
    findings += _ast_check_unprotected_state_change(ast_json)
    findings += _ast_check_events_missing(ast_json)
    findings += _ast_check_unchecked_external(ast_json)

    _print(f"AST analysis: {len(findings)} finding(s).", "green")
    return findings


# ── AST helper ───────────────────────────────────────────────────────────────

def _ast_walk(node, node_type: str) -> list[dict]:
    """Yield all AST nodes of a given nodeType, depth-first."""
    collected = []
    if not isinstance(node, dict):
        return collected
    if node.get("nodeType") == node_type:
        collected.append(node)
    for child in node.get("nodes", []) + [node.get(k) for k in (
        "body", "expression", "leftHandSide", "rightHandSide",
        "trueBody", "falseBody", "subExpression",
    ) if node.get(k)]:
        if isinstance(child, dict):
            collected += _ast_walk(child, node_type)
        elif isinstance(child, list):
            for item in child:
                collected += _ast_walk(item, node_type)
    return collected


def _ast_src_line(node: dict) -> str:
    """Return a human-readable source location from an AST node."""
    src = node.get("src", "")
    if src:
        parts = src.split(":")
        if len(parts) >= 2:
            return f"byte offset {parts[0]}, length {parts[1]}"
    return node.get("name", "unknown")


def _ast_check_state_mutability(ast: dict) -> list[dict]:
    """Detect public/external functions that modify state but lack access control."""
    findings = []
    for fn in _ast_walk(ast, "FunctionDefinition"):
        visibility = fn.get("visibility", "")
        mutability = fn.get("stateMutability", "")
        name = fn.get("name", "")
        # Skip view/pure, constructors, events
        if mutability in ("view", "pure") or not name:
            continue
        if visibility not in ("public", "external"):
            continue
        # Check if the function body modifies state variables
        body = fn.get("body", {})
        if body is None:
            continue
        assignments = _ast_walk(body, "Assignment")
        if not assignments:
            continue
        # Check modifiers for access control
        mods = [m.get("modifierName", {}).get("name", "") for m in fn.get("modifiers", [])]
        has_ac = any(
            k in " ".join(mods).lower()
            for k in ("onlyowner", "onlyrole", "onlyadmin", "whennotpaused", "auth")
        )
        if not has_ac:
            findings.append({
                "type":           "ast_unprotected_state_fn",
                "severity":       "Medium",
                "description":    (
                    f"AST: Public/external function '{name}' modifies state "
                    "without visible access-control modifier."
                ),
                "location":       _ast_src_line(fn),
                "recommendation": (
                    "Add onlyOwner, onlyRole, or a custom access-control modifier "
                    "to state-modifying public functions."
                ),
                "tool":   "AST",
                "swc_id": "SWC-100",
                "cvss_score":  5.3,
                "cvss_vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:M/A:N",
            })
    return findings


def _ast_check_missing_zero_address(ast: dict) -> list[dict]:
    """Detect constructor/setter parameters of type 'address' with no zero-address check."""
    findings = []
    for fn in _ast_walk(ast, "FunctionDefinition"):
        is_ctor = fn.get("kind") == "constructor"
        name = fn.get("name", "") or "constructor"
        params = fn.get("parameters", {}).get("parameters", [])
        addr_params = [
            p.get("name", "?")
            for p in params
            if isinstance(p.get("typeName"), dict)
            and p["typeName"].get("name") == "address"
        ]
        if not addr_params:
            continue
        body = fn.get("body", {})
        body_str = json.dumps(body)
        missing = [
            p for p in addr_params
            if f"address(0)" not in body_str and p not in body_str.replace("address(0)", "")
            or "address(0)" not in body_str
        ]
        # Simple heuristic: if "address(0)" does not appear in the function body at all
        if "address(0)" not in body_str and addr_params:
            findings.append({
                "type":           "ast_missing_zero_address_check",
                "severity":       "Low",
                "description":    (
                    f"AST: Function '{name}' accepts address parameter(s) "
                    f"{addr_params} without a visible zero-address guard."
                ),
                "location":       _ast_src_line(fn),
                "recommendation": (
                    "Add require(param != address(0), \"Zero address\") "
                    "for all address parameters."
                ),
                "tool":   "AST",
                "swc_id": "N/A",
                "cvss_score":  3.1,
                "cvss_vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:L/A:N",
            })
    return findings


def _ast_check_unprotected_state_change(ast: dict) -> list[dict]:
    """Detect storage writes in fallback/receive functions."""
    findings = []
    for fn in _ast_walk(ast, "FunctionDefinition"):
        kind = fn.get("kind", "")
        if kind not in ("fallback", "receive"):
            continue
        body = fn.get("body", {})
        if body and _ast_walk(body, "Assignment"):
            findings.append({
                "type":           "ast_fallback_state_write",
                "severity":       "High",
                "description":    (
                    f"AST: {kind}() function writes to storage. "
                    "This can be exploited by sending ETH or call data."
                ),
                "location":       _ast_src_line(fn),
                "recommendation": "Avoid state changes in fallback/receive; use dedicated functions.",
                "tool":   "AST",
                "swc_id": "SWC-132",
                "cvss_score":  7.5,
                "cvss_vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N",
            })
    return findings


def _ast_check_events_missing(ast: dict) -> list[dict]:
    """Detect critical state-changing functions that emit no events."""
    findings = []
    critical_names_re = re.compile(
        r"^(mint|burn|transfer|withdraw|deposit|setOwner|pause|upgrade|initialize)$",
        re.IGNORECASE,
    )
    for fn in _ast_walk(ast, "FunctionDefinition"):
        name = fn.get("name", "")
        if not critical_names_re.match(name):
            continue
        if fn.get("stateMutability") in ("view", "pure"):
            continue
        body = fn.get("body", {})
        if body and not _ast_walk(body, "EmitStatement"):
            findings.append({
                "type":           "ast_missing_event",
                "severity":       "Low",
                "description":    (
                    f"AST: Critical function '{name}' does not emit any event. "
                    "Off-chain monitoring and indexing will be blind to state changes."
                ),
                "location":       _ast_src_line(fn),
                "recommendation": f"Add an event (e.g. emit {name.capitalize()}(...)) for off-chain traceability.",
                "tool":   "AST",
                "swc_id": "N/A",
                "cvss_score":  2.5,
                "cvss_vector": "AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:L/A:N",
            })
    return findings


def _ast_check_unchecked_external(ast: dict) -> list[dict]:
    """Detect low-level .call() nodes where the return value is discarded (ExpressionStatement wrapping a FunctionCall with .call)."""
    findings = []
    for expr_stmt in _ast_walk(ast, "ExpressionStatement"):
        expr = expr_stmt.get("expression", {})
        # A bare call not assigned: expression is a FunctionCall, not an Assignment
        if expr.get("nodeType") != "FunctionCall":
            continue
        expr_str = json.dumps(expr)
        if '"memberName": "call"' in expr_str or '"memberName": "send"' in expr_str:
            findings.append({
                "type":           "ast_unchecked_low_level_call",
                "severity":       "High",
                "description":    (
                    "AST: Low-level .call() or .send() return value is not captured — "
                    "failures are silently ignored."
                ),
                "location":       _ast_src_line(expr_stmt),
                "recommendation": "Capture (bool success,) = addr.call{...}(\"\"); require(success);",
                "tool":   "AST",
                "swc_id": "SWC-104",
                "cvss_score":  7.5,
                "cvss_vector": "AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N",
            })
    return findings

BUG_FIX_GUIDES: dict[str, dict] = {
    "reentrancy": {
        "title": "Reentrancy",
        "explanation": (
            "A reentrancy attack lets a malicious contract call back into your function "
            "before the first execution finishes, draining funds or corrupting state. "
            "Fix: update all state variables BEFORE making any external call, and "
            "use OpenZeppelin ReentrancyGuard as an additional safeguard."
        ),
        "bad": (
            "// VULNERABLE — state updated AFTER the external call\n"
            "function withdraw(uint amount) external {\n"
            "    require(balances[msg.sender] >= amount);\n"
            "    (bool ok, ) = msg.sender.call{value: amount}(\"\");  // attacker re-enters here\n"
            "    require(ok);\n"
            "    balances[msg.sender] -= amount;   // never reached on re-entry\n"
            "}"
        ),
        "good": (
            "// FIXED — checks-effects-interactions + ReentrancyGuard\n"
            "import \"@openzeppelin/contracts/security/ReentrancyGuard.sol\";\n\n"
            "contract Safe is ReentrancyGuard {\n"
            "    function withdraw(uint amount) external nonReentrant {\n"
            "        require(balances[msg.sender] >= amount, \"Insufficient\");\n"
            "        balances[msg.sender] -= amount;          // effect first\n"
            "        (bool ok, ) = msg.sender.call{value: amount}(\"\");\n"
            "        require(ok, \"Transfer failed\");\n"
            "    }\n"
            "}"
        ),
    },
    "unsafe_call": {
        "title": "Unsafe External Call",
        "explanation": (
            ".call() returns (bool success, bytes memory data). "
            "Ignoring the bool silently swallows failures. "
            "Always check the return value and guard against reentrancy."
        ),
        "bad": (
            "// VULNERABLE — return value ignored\n"
            "target.call{value: amount}(data);"
        ),
        "good": (
            "// FIXED — check return value\n"
            "(bool success, ) = target.call{value: amount}(data);\n"
            "require(success, \"External call failed\");"
        ),
    },
    "tx_origin": {
        "title": "tx.origin Authentication",
        "explanation": (
            "tx.origin is always the EOA that started the full transaction chain. "
            "A phishing contract can call yours on behalf of the victim — "
            "tx.origin still equals the victim. Always use msg.sender for auth."
        ),
        "bad": (
            "// VULNERABLE\n"
            "require(tx.origin == owner, \"Not owner\");"
        ),
        "good": (
            "// FIXED\n"
            "require(msg.sender == owner, \"Not owner\");\n"
            "// Or use OpenZeppelin Ownable:\n"
            "// import \"@openzeppelin/contracts/access/Ownable.sol\";"
        ),
    },
    "block_timestamp": {
        "title": "Block Timestamp Dependency",
        "explanation": (
            "Validators can nudge block.timestamp by up to ~15 seconds. "
            "Never use it for exact equality checks or as randomness. "
            "For time-locks, compare with >= and allow a reasonable tolerance."
        ),
        "bad": (
            "// VULNERABLE — exact equality is manipulable\n"
            "require(block.timestamp == unlockTime, \"Not yet\");"
        ),
        "good": (
            "// FIXED — inequality with tolerance\n"
            "uint constant TOLERANCE = 15 seconds;\n"
            "require(block.timestamp >= unlockTime - TOLERANCE, \"Not yet\");"
        ),
    },
    "delegatecall": {
        "title": "Delegatecall Storage Collision",
        "explanation": (
            "delegatecall executes the target's code in the caller's storage context. "
            "If storage layouts differ, variables alias each other. "
            "Use EIP-1967 unstructured storage slots for proxy implementations."
        ),
        "bad": (
            "// VULNERABLE — raw delegatecall, no layout guarantee\n"
            "(bool ok, ) = implementation.delegatecall(msg.data);"
        ),
        "good": (
            "// FIXED — EIP-1967 slot keeps impl address out of collision zone\n"
            "bytes32 constant IMPL_SLOT =\n"
            "    0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc;\n\n"
            "fallback() external payable {\n"
            "    address impl;\n"
            "    assembly { impl := sload(IMPL_SLOT) }\n"
            "    assembly {\n"
            "        calldatacopy(0, 0, calldatasize())\n"
            "        let result := delegatecall(gas(), impl, 0, calldatasize(), 0, 0)\n"
            "        returndatacopy(0, 0, returndatasize())\n"
            "        switch result\n"
            "        case 0 { revert(0, returndatasize()) }\n"
            "        default { return(0, returndatasize()) }\n"
            "    }\n"
            "}"
        ),
    },
    "assert_usage": {
        "title": "Assert Instead of Require",
        "explanation": (
            "assert() consumes ALL remaining gas and is for internal invariants "
            "that should never be false in correct code. "
            "require() refunds unused gas and is correct for input validation."
        ),
        "bad": (
            "// WRONG — assert for input validation burns all gas\n"
            "assert(amount > 0);\n"
            "assert(msg.sender != address(0));"
        ),
        "good": (
            "// FIXED — require() for validation\n"
            "require(amount > 0, \"Amount must be positive\");\n"
            "require(msg.sender != address(0), \"Zero address\");\n"
            "// assert() only for internal invariants:\n"
            "assert(totalSupply == sumOfBalances);"
        ),
    },
    "unbounded_loop": {
        "title": "Unbounded Loop / DoS",
        "explanation": (
            "A loop over an unbounded array can exceed the block gas limit, "
            "permanently bricking the function. "
            "Use a pull-payment pattern or paginated batches."
        ),
        "bad": (
            "// VULNERABLE — array grows without bound\n"
            "address[] public users;\n"
            "function payAll() external {\n"
            "    for (uint i = 0; i < users.length; i++) {\n"
            "        payable(users[i]).transfer(share);\n"
            "    }\n"
            "}"
        ),
        "good": (
            "// FIXED — pull-payment pattern\n"
            "mapping(address => uint) public pending;\n\n"
            "function withdraw() external {\n"
            "    uint amount = pending[msg.sender];\n"
            "    require(amount > 0);\n"
            "    pending[msg.sender] = 0;\n"
            "    payable(msg.sender).transfer(amount);\n"
            "}\n\n"
            "// OR batched with explicit limits\n"
            "function payBatch(uint start, uint end) external {\n"
            "    require(end <= users.length && end - start <= 100);\n"
            "    for (uint i = start; i < end; i++) {\n"
            "        payable(users[i]).transfer(share);\n"
            "    }\n"
            "}"
        ),
    },
    "hardcoded_address": {
        "title": "Hardcoded Address",
        "explanation": (
            "Hardcoded addresses break on testnets, forks, and re-deployments. "
            "Pass addresses via constructor and store them in immutable variables."
        ),
        "bad": (
            "// FRAGILE\n"
            "IERC20 token = IERC20(0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48);"
        ),
        "good": (
            "// FIXED — set at deploy time\n"
            "IERC20 public immutable token;\n"
            "constructor(address _token) {\n"
            "    require(_token != address(0), \"Zero address\");\n"
            "    token = IERC20(_token);\n"
            "}"
        ),
    },
    "frontrunning": {
        "title": "Frontrunning Vulnerability",
        "explanation": (
            "Transactions sit in the mempool before inclusion. "
            "Bots watch for profitable patterns and insert their own tx first. "
            "Use commit-reveal: commit a hash now, reveal the value next block."
        ),
        "bad": (
            "// VULNERABLE — plaintext value visible in mempool\n"
            "function guess(uint secret) external payable {\n"
            "    require(secret == answer, \"Wrong\");\n"
            "    payable(msg.sender).transfer(prize);\n"
            "}"
        ),
        "good": (
            "// FIXED — commit-reveal scheme\n"
            "mapping(address => bytes32) public commits;\n\n"
            "function commit(bytes32 hash) external {\n"
            "    commits[msg.sender] = hash;\n"
            "}\n\n"
            "function reveal(uint secret, bytes32 salt) external {\n"
            "    require(commits[msg.sender] ==\n"
            "        keccak256(abi.encodePacked(secret, salt)));\n"
            "    require(secret == answer, \"Wrong\");\n"
            "    delete commits[msg.sender];\n"
            "    payable(msg.sender).transfer(prize);\n"
            "}"
        ),
    },
    "assembly_storage": {
        "title": "Inline Assembly Storage Access",
        "explanation": (
            "Raw assembly bypasses Solidity's type and bounds checking. "
            "Restrict it to well-audited minimal patterns. "
            "Always document the storage slot with a NatSpec comment."
        ),
        "bad": (
            "// RISKY — arbitrary slot write\n"
            "assembly { sstore(slot, value) }"
        ),
        "good": (
            "// SAFE — named constant slot with documentation\n"
            "/// @dev EIP-1967 implementation slot\n"
            "bytes32 private constant _IMPL_SLOT =\n"
            "    0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc;\n\n"
            "function _setImpl(address newImpl) internal {\n"
            "    assembly { sstore(_IMPL_SLOT, newImpl) }\n"
            "}"
        ),
    },
    "dos_external_calls": {
        "title": "DoS via External Calls",
        "explanation": (
            "Sending ETH to a list of addresses lets one reverting recipient block "
            "everyone else. Use the pull-payment pattern: credit balances, "
            "let users withdraw themselves."
        ),
        "bad": (
            "// VULNERABLE — one revert blocks all payments\n"
            "for (uint i; i < winners.length; i++) {\n"
            "    winners[i].transfer(prize);\n"
            "}"
        ),
        "good": (
            "// FIXED — pull-payment (OpenZeppelin PullPayment)\n"
            "import \"@openzeppelin/contracts/security/PullPayment.sol\";\n\n"
            "contract Lottery is PullPayment {\n"
            "    function awardPrize(address winner) internal {\n"
            "        _asyncTransfer(winner, prize);\n"
            "    }\n"
            "    // winner calls withdrawPayments(payable(msg.sender))\n"
            "}"
        ),
    },
    "unchecked_call_returns": {
        "title": "Unchecked Call Return Value",
        "explanation": (
            "Low-level .call() does NOT revert on failure — it returns false. "
            "Always capture and check the bool return value."
        ),
        "bad": (
            "// SILENT FAILURE\n"
            "addr.call{value: 1 ether}(\"\");"
        ),
        "good": (
            "// FIXED — always check\n"
            "(bool success, ) = addr.call{value: 1 ether}(\"\");\n"
            "require(success, \"ETH transfer failed\");"
        ),
    },
    "weak_randomness": {
        "title": "Weak On-chain Randomness",
        "explanation": (
            "block.timestamp, blockhash, and block.number are predictable or "
            "manipulable by validators. Use Chainlink VRF for verifiable randomness."
        ),
        "bad": (
            "// MANIPULABLE\n"
            "uint rand = uint(keccak256(abi.encodePacked(\n"
            "    block.timestamp, block.difficulty)));"
        ),
        "good": (
            "// FIXED — Chainlink VRF v2\n"
            "import \"@chainlink/contracts/src/v0.8/VRFConsumerBaseV2.sol\";\n\n"
            "contract FairDraw is VRFConsumerBaseV2 {\n"
            "    function requestRandom() external returns (uint256 reqId) {\n"
            "        return COORDINATOR.requestRandomWords(\n"
            "            keyHash, subscriptionId, 3, 100_000, 1);\n"
            "    }\n"
            "    function fulfillRandomWords(uint256, uint256[] memory words)\n"
            "        internal override {\n"
            "        winner = participants[words[0] % participants.length];\n"
            "    }\n"
            "}"
        ),
    },
    "flash_loan": {
        "title": "Flash Loan Attack Vector",
        "explanation": (
            "Flash loans let attackers temporarily control massive token amounts "
            "within one transaction, manipulating prices or balances. "
            "Use TWAP price feeds and validate balances before and after operations."
        ),
        "bad": (
            "// VULNERABLE — spot price manipulable with flash loan\n"
            "uint price = token.balanceOf(pool) / weth.balanceOf(pool);"
        ),
        "good": (
            "// FIXED — Uniswap V3 TWAP oracle\n"
            "(int24 tick, ) = OracleLibrary.consult(pool, twapInterval);\n"
            "uint price = OracleLibrary.getQuoteAtTick(\n"
            "    tick, 1e18, tokenIn, tokenOut);"
        ),
    },
    "oracle_manipulation": {
        "title": "Oracle Price Manipulation",
        "explanation": (
            "Single-block spot-price reads can be manipulated in the same tx. "
            "Use Chainlink data feeds with staleness checks, or Uniswap V3 TWAP."
        ),
        "bad": (
            "// VULNERABLE — spot price, manipulable in one block\n"
            "function getPrice() public view returns (uint) {\n"
            "    return pair.token0Balance() * 1e18 / pair.token1Balance();\n"
            "}"
        ),
        "good": (
            "// FIXED — Chainlink with staleness guard\n"
            "AggregatorV3Interface feed = AggregatorV3Interface(priceFeed);\n"
            "(, int256 price, , uint256 updatedAt, ) = feed.latestRoundData();\n"
            "require(block.timestamp - updatedAt <= 3600, \"Stale price\");\n"
            "require(price > 0, \"Invalid price\");"
        ),
    },
    "unsafe_math": {
        "title": "Unsafe Arithmetic",
        "explanation": (
            "Solidity < 0.8 silently wraps on overflow/underflow. "
            "In >= 0.8 arithmetic reverts by default, but unchecked{} blocks "
            "disable this. Only use unchecked when you can prove no overflow."
        ),
        "bad": (
            "// VULNERABLE — Solidity <0.8, silent overflow\n"
            "uint8 x = 255;\n"
            "x += 1;  // wraps to 0"
        ),
        "good": (
            "// FIXED A: use Solidity >= 0.8 (reverts on overflow)\n"
            "pragma solidity ^0.8.20;\n\n"
            "// FIXED B: Solidity <0.8 — SafeMath\n"
            "using SafeMath for uint256;\n"
            "uint256 result = a.add(b);\n\n"
            "// FIXED C: unchecked only when provably safe\n"
            "for (uint256 i; i < arr.length; ++i) {\n"
            "    unchecked { i++; }  // safe: bounded by arr.length\n"
            "}"
        ),
    },
    "unlimited_mint": {
        "title": "Unprotected Mint Function",
        "explanation": (
            "A mint() function without access control lets anyone create unlimited "
            "tokens, instantly collapsing the token's value. "
            "Gate mint with onlyOwner or a role."
        ),
        "bad": (
            "// VULNERABLE — anyone can mint\n"
            "function mint(uint256 amount) external {\n"
            "    _mint(msg.sender, amount);\n"
            "}"
        ),
        "good": (
            "// FIXED — OpenZeppelin Ownable\n"
            "import \"@openzeppelin/contracts/access/Ownable.sol\";\n\n"
            "contract MyToken is ERC20, Ownable {\n"
            "    function mint(address to, uint256 amount)\n"
            "        external onlyOwner {\n"
            "        _mint(to, amount);\n"
            "    }\n"
            "}"
        ),
    },
    "proxy_issues": {
        "title": "Proxy Storage Collision",
        "explanation": (
            "A proxy storing its implementation address at slot 0 will collide "
            "with the implementation contract's first variable. "
            "Use the EIP-1967 dedicated storage slots."
        ),
        "bad": (
            "// VULNERABLE — slot 0 collides with impl's first variable\n"
            "address implementation;   // slot 0"
        ),
        "good": (
            "// FIXED — EIP-1967 unstructured storage\n"
            "bytes32 constant IMPL_SLOT =\n"
            "    0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc;\n\n"
            "function _setImpl(address newImpl) internal {\n"
            "    require(newImpl.code.length > 0, \"Not a contract\");\n"
            "    assembly { sstore(IMPL_SLOT, newImpl) }\n"
            "}"
        ),
    },
    "missing_pragma": {
        "title": "Missing Solidity Version Pragma",
        "explanation": (
            "Without a pragma the file compiles with whatever solc is installed, "
            "which may be incompatible. Always declare the Solidity version."
        ),
        "bad": (
            "// No pragma — compiler version unknown\n"
            "contract MyContract { }"
        ),
        "good": (
            "// FIXED — lock to a tested, modern version\n"
            "pragma solidity 0.8.20;\n"
            "contract MyContract { }"
        ),
    },
    "floating_pragma": {
        "title": "Floating Pragma",
        "explanation": (
            "pragma solidity ^0.8.x allows any 0.8.x compiler. "
            "Different compiler versions may produce different bytecode or expose bugs. "
            "Lock to an exact version for production."
        ),
        "bad": (
            "// FLOATING — could compile with 0.8.0 through 0.8.99\n"
            "pragma solidity ^0.8.0;"
        ),
        "good": (
            "// FIXED — pinned to audited version\n"
            "pragma solidity 0.8.20;"
        ),
    },
    "outdated_solidity_version": {
        "title": "Outdated Solidity (< 0.8.0)",
        "explanation": (
            "Solidity before 0.8.0 has no built-in overflow protection and many "
            "resolved compiler bugs. Upgrade to 0.8.20+ and remove SafeMath."
        ),
        "bad":  "pragma solidity ^0.6.0;  // no overflow protection",
        "good": "pragma solidity 0.8.20;  // built-in overflow checks",
    },
    "vulnerable_solidity_version": {
        "title": "Vulnerable Solidity Version (0.8.0–0.8.15)",
        "explanation": (
            "These versions have known compiler bugs including ABI encoding issues "
            "and optimiser problems. Upgrade to 0.8.20 or later."
        ),
        "bad":  "pragma solidity ^0.8.12;  // affected by known compiler bugs",
        "good": "pragma solidity 0.8.20;   // all known bugs fixed",
    },
    "slightly_outdated_solidity_version": {
        "title": "Slightly Outdated Solidity (0.8.16–0.8.18)",
        "explanation": (
            "0.8.17 introduced a storage-read bug under the Yul optimizer. "
            "Upgrade to 0.8.20+ to benefit from all fixes."
        ),
        "bad":  "pragma solidity 0.8.17;",
        "good": "pragma solidity 0.8.20;",
    },
    "deprecated_function": {
        "title": "Deprecated Solidity Construct",
        "explanation": (
            "throw, suicide, sha3, callcode, block.blockhash, and selfdestruct "
            "are deprecated or removed in modern Solidity. "
            "Replace with current equivalents."
        ),
        "bad": (
            "// DEPRECATED\n"
            "if (!condition) throw;\n"
            "selfdestruct(owner);\n"
            "bytes32 h = sha3(data);"
        ),
        "good": (
            "// FIXED — modern equivalents\n"
            "require(condition, \"Failed\");\n"
            "// selfdestruct: remove or use a withdrawal pattern\n"
            "bytes32 h = keccak256(data);"
        ),
    },
    "selfdestruct": {
        "title": "Unprotected selfdestruct",
        "explanation": (
            "selfdestruct destroys the contract and sends all ETH to the target. "
            "If callable by anyone, attackers can permanently destroy the contract. "
            "Restrict with onlyOwner and consider removing it entirely — "
            "EIP-6049 deprecated selfdestruct in 2023."
        ),
        "bad": (
            "// VULNERABLE — anyone can destroy the contract\n"
            "function kill() external {\n"
            "    selfdestruct(payable(msg.sender));\n"
            "}"
        ),
        "good": (
            "// FIXED — restrict or remove entirely\n"
            "function kill() external onlyOwner {\n"
            "    // Consider: emit an event and use a withdrawal pattern instead\n"
            "    selfdestruct(payable(owner()));\n"
            "}"
        ),
    },
    "initialize_unprotected": {
        "title": "Unprotected initialize() Function",
        "explanation": (
            "Proxy contracts use initialize() instead of constructors. "
            "If not protected, anyone can call it first and take ownership. "
            "Use OpenZeppelin Initializable with the initializer modifier."
        ),
        "bad": (
            "// VULNERABLE — anyone can initialize\n"
            "function initialize(address _owner) public {\n"
            "    owner = _owner;\n"
            "}"
        ),
        "good": (
            "// FIXED — OpenZeppelin Initializable\n"
            "import \"@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol\";\n\n"
            "contract MyProxy is Initializable {\n"
            "    function initialize(address _owner) public initializer {\n"
            "        __Ownable_init();\n"
            "        owner = _owner;\n"
            "    }\n"
            "}"
        ),
    },
    "ecrecover": {
        "title": "ecrecover Signature Malleability / Zero Address",
        "explanation": (
            "ecrecover returns address(0) on failure — never check against zero. "
            "Also vulnerable to signature malleability (s-value flipping). "
            "Use OpenZeppelin ECDSA library which handles both issues."
        ),
        "bad": (
            "// VULNERABLE\n"
            "address signer = ecrecover(hash, v, r, s);\n"
            "require(signer == owner, \"Invalid sig\");"
        ),
        "good": (
            "// FIXED — OpenZeppelin ECDSA\n"
            "import \"@openzeppelin/contracts/utils/cryptography/ECDSA.sol\";\n\n"
            "using ECDSA for bytes32;\n"
            "address signer = hash.toEthSignedMessageHash().recover(signature);\n"
            "require(signer != address(0) && signer == owner, \"Invalid sig\");"
        ),
    },
    "approve_race": {
        "title": "ERC-20 approve() Race Condition",
        "explanation": (
            "approve(spender, amount) is vulnerable to a race condition. "
            "If you change allowance from N to M, spender can spend N+M "
            "by front-running the second approval. "
            "Use increaseAllowance/decreaseAllowance instead."
        ),
        "bad": (
            "// VULNERABLE — race condition\n"
            "token.approve(spender, newAmount);"
        ),
        "good": (
            "// FIXED — use increaseAllowance\n"
            "// First reset to 0, then set new value:\n"
            "token.approve(spender, 0);\n"
            "token.approve(spender, newAmount);\n"
            "// Or use OpenZeppelin SafeERC20:\n"
            "import \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\";\n"
            "safeToken.safeIncreaseAllowance(spender, amount);"
        ),
    },
    "abi_encode_packed": {
        "title": "abi.encodePacked Hash Collision",
        "explanation": (
            "abi.encodePacked with multiple dynamic types (string, bytes, arrays) "
            "can produce identical results for different inputs. "
            "Example: encodePacked(\"aa\",\"bb\") == encodePacked(\"a\",\"abb\"). "
            "Use abi.encode() instead."
        ),
        "bad": (
            "// COLLISION RISK\n"
            "bytes32 h = keccak256(abi.encodePacked(str1, str2));"
        ),
        "good": (
            "// FIXED — use abi.encode\n"
            "bytes32 h = keccak256(abi.encode(str1, str2));"
        ),
    },
    "signature_replay": {
        "title": "Signature Replay Attack",
        "explanation": (
            "A valid signature can be reused in multiple transactions "
            "unless you include a nonce and chain ID in the signed message. "
            "Use EIP-712 structured data signing with nonces."
        ),
        "bad": (
            "// VULNERABLE — no nonce, no chainId\n"
            "bytes32 hash = keccak256(abi.encode(amount, receiver));\n"
            "address signer = ECDSA.recover(hash, sig);"
        ),
        "good": (
            "// FIXED — EIP-712 with nonce and chainId\n"
            "bytes32 hash = keccak256(abi.encode(\n"
            "    TYPE_HASH, amount, receiver,\n"
            "    nonces[msg.sender]++,\n"
            "    block.chainid\n"
            "));\n"
            "address signer = ECDSA.recover(\n"
            "    _hashTypedDataV4(hash), sig\n"
            ");"
        ),
    },
    "price_manipulation": {
        "title": "AMM Spot Price Manipulation",
        "explanation": (
            "Reading reserves directly from an AMM pool (getReserves, balanceOf) "
            "gives a spot price manipulable in the same transaction via flash loans. "
            "Use a TWAP oracle or Chainlink price feed."
        ),
        "bad": (
            "// VULNERABLE — spot price from reserves\n"
            "(uint112 reserve0, uint112 reserve1,) = pair.getReserves();\n"
            "uint price = reserve0 / reserve1;"
        ),
        "good": (
            "// FIXED — Uniswap V3 TWAP\n"
            "uint32[] memory secondsAgos = new uint32[](2);\n"
            "secondsAgos[0] = 1800; // 30 min TWAP\n"
            "secondsAgos[1] = 0;\n"
            "(int56[] memory ticks,) = pool.observe(secondsAgos);\n"
            "int24 avgTick = int24((ticks[1] - ticks[0]) / 1800);"
        ),
    },
    "unchecked_block": {
        "title": "unchecked Block — Overflow Risk",
        "explanation": (
            "unchecked{} disables Solidity 0.8+ overflow protection. "
            "Only use it when you have mathematically proven no overflow is possible. "
            "Incorrect use reintroduces silent overflow bugs from Solidity <0.8."
        ),
        "bad": (
            "// RISKY — unchecked without proof\n"
            "unchecked {\n"
            "    balances[from] -= amount;  // could underflow if not checked above\n"
            "}"
        ),
        "good": (
            "// SAFE — only use after explicit bounds check\n"
            "require(balances[from] >= amount, \"Insufficient\");\n"
            "unchecked {\n"
            "    balances[from] -= amount;  // safe: checked on line above\n"
            "}"
        ),
    },
    "silent_overflow": {
        "title": "Silent Overflow in unchecked Block",
        "explanation": (
            "Arithmetic inside unchecked{} silently wraps on overflow/underflow. "
            "Ensure all values are bounded before entering unchecked scope."
        ),
        "bad": (
            "unchecked { total += amounts[i]; }  // total can silently overflow"
        ),
        "good": (
            "require(total + amounts[i] >= total, \"Overflow\");\n"
            "unchecked { total += amounts[i]; }"
        ),
    },
    "erc20_unchecked": {
        "title": "Unchecked ERC-20 transfer() Return Value",
        "explanation": (
            "Some ERC-20 tokens (e.g. USDT) return false instead of reverting on failure. "
            "Ignoring the return value silently loses tokens. "
            "Use OpenZeppelin SafeERC20."
        ),
        "bad": (
            "// SILENT FAILURE for non-standard tokens\n"
            "token.transfer(recipient, amount);"
        ),
        "good": (
            "// FIXED — SafeERC20\n"
            "import \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\";\n\n"
            "using SafeERC20 for IERC20;\n"
            "token.safeTransfer(recipient, amount);"
        ),
    },
    "eth_transfer_old": {
        "title": "payable.transfer() — 2300 Gas Limit",
        "explanation": (
            "address.transfer() hard-limits gas to 2300, which breaks "
            "if the recipient is a contract with a non-trivial receive(). "
            "Use call{value:} with a return-value check instead."
        ),
        "bad": (
            "// FRAGILE — breaks with smart contract recipients\n"
            "payable(recipient).transfer(amount);"
        ),
        "good": (
            "// FIXED — use call with check\n"
            "(bool ok, ) = payable(recipient).call{value: amount}(\"\");\n"
            "require(ok, \"ETH transfer failed\");"
        ),
    },
}

# ─────────────────────────────────────────────────────────────────────────────
#  REGEX PATTERNS
# ─────────────────────────────────────────────────────────────────────────────

PATTERNS: dict = {
    "unsafe_call":            re.compile(r'\.call\s*\(|\.call\.value\s*\('),
    "flash_loan":             re.compile(r'\btransferFrom\b.*\b(msg\.sender|tx\.origin)\b'),
    "oracle_manipulation":    re.compile(r'\b(getPrice|priceFeed)\b'),
    "tx_origin":              re.compile(r'\btx\.origin\b'),
    "unsafe_math":            re.compile(r'\b[-+*/]\b.*uint'),
    "block_timestamp":        re.compile(r'\bblock\.timestamp\b'),
    "delegatecall":           re.compile(r'\bdelegatecall\b'),
    "assert_usage":           re.compile(r'\bassert\b'),
    "unbounded_loop":         re.compile(r'\bfor\s*\(.*;.*;\s*\)'),
    "hardcoded_address":      re.compile(r'0x[a-fA-F0-9]{40}'),
    "frontrunning":           re.compile(r'\b(msg\.sender|tx\.origin)\b.*\b(storage|memory)\b.*='),
    "assembly_storage":       re.compile(r'\basm\b.*\bstorage\b', re.IGNORECASE),
    "dos_external_calls":     re.compile(r'\b(call|transfer)\b.*\bexternal\b|\.transfer\s*\('),
    "unchecked_call_returns": re.compile(r'\.call\b.*\([^)]*\)\s*;'),
    "weak_randomness":        re.compile(r'\b(blockhash|block\.timestamp|block\.number)\b.*\b(random|rand)\b'),
    "reentrancy":             re.compile(r'\.call\b|\.transfer\b|\.send\b'),
    "mint_function":          re.compile(r'\bfunction\s+mint\b.*\b(uint|uint256)\s+amount\b'),
    "only_owner":             re.compile(r'\brequire\s*\(\s*msg\.sender\s*==\s*owner\b|\bmodifier\s+onlyOwner\b'),
    "role_based":             re.compile(r'\bhasRole\b|\bgrantRole\b|\bAccessControl\b'),
    "proxy_delegatecall":     re.compile(r'\bfallback\s*\(\)\s*external\b.*\bdelegatecall\b'),
    "implementation_storage": re.compile(
        r'\bstorage\s+address\s+_implementation\b|\bslot\s*=\s*keccak256\b.*implementation'
    ),
    "solidity_version":       re.compile(r'pragma\s+solidity\s+\^?(\d+\.\d+\.\d+)'),
    # ── Новые паттерны (расширенное покрытие) ────────────────────────────────
    "selfdestruct":           re.compile(r'\bselfdestruct\s*\('),
    "initialize_unprotected": re.compile(r'\bfunction\s+init(?:ialize)?\s*\('),
    "eth_transfer_old":       re.compile(r'\bpayable\s*\(.*\)\.transfer\s*\('),
    "ecrecover":              re.compile(r'\becrecover\s*\('),
    "msg_value_loop":         re.compile(r'\bfor\b[^}]*\bmsg\.value\b'),
    "approve_race":           re.compile(r'\bapprove\s*\([^)]+,\s*[^0][^)]*\)'),
    "block_number_time":      re.compile(r'\bblock\.number\b'),
    "single_owner_control":   re.compile(r'\bonlyOwner\b'),
    "abi_encode_packed":      re.compile(r'\babi\.encodePacked\s*\('),
    "erc20_unchecked":        re.compile(r'\b(?:token|erc20|IERC20)\b.*\.\s*(?:transfer|transferFrom)\s*\([^;]+\)\s*;'),
    "open_receive":           re.compile(r'\breceive\s*\(\s*\)\s*external\s+payable'),
    "integer_division":       re.compile(r'\b\w+\s*/\s*\w+\b'),
    "missing_event_owner":    re.compile(r'\bfunction\s+\w+\s*\([^)]*\)\s*(?:external|public)\s+(?:onlyOwner|onlyRole)\b'),
    "unchecked_block":        re.compile(r'\bunchecked\s*\{'),
    "low_level_call":         re.compile(r'\b(?:call|staticcall|delegatecall)\s*\{[^}]*\}'),
    "signature_replay":       re.compile(r'\becrecover\b[^;]*;'),
    "msg_sender_delegatecall":re.compile(r'\bdelegatecall\b.*\bmsg\.sender\b|\bmsg\.sender\b.*\bdelegatecall\b'),
    "storage_collision":      re.compile(r'\bstorage\b[^;]*\bslot\b'),
    "erc721_transfer":        re.compile(r'\b(?:safeTransferFrom|transferFrom)\s*\('),
    "price_manipulation":     re.compile(r'\breserve[01]\b|\bgetReserves\b|\btoken[01]\b.*\bbalanceOf\b'),
    "ownership_transfer":     re.compile(r'\btransferOwnership\s*\('),
    "zero_address_check":     re.compile(r'address\s*\(0\)|address\(0x0\)'),
    "silent_overflow":        re.compile(r'\bunchecked\s*\{[^}]*(?:\+\+|--|\ \+\ |\ -\ )[^}]*\}'),
}

DEPRECATED_PATTERNS: list = [
    re.compile(r'\bthrow\b'),
    re.compile(r'\bsuicide\b'),
    re.compile(r'\bblock\.blockhash\b'),
    re.compile(r'\bsha3\b'),
    re.compile(r'\bcallcode\b'),
    re.compile(r'\bselfdestruct\b'),
]

# Line-level checks: (pattern_key, title, description, recommendation, severity)
LINE_CHECKS: list[tuple] = [
    ("unsafe_call", "Unsafe External Call", "Unsafe .call / .call.value detected without reentrancy protection.", "Use ReentrancyGuard (OpenZeppelin) and follow checks-effects-interactions.", "High"),
    ("tx_origin", "tx.origin Authentication", "tx.origin is used for authentication.", "Replace with msg.sender for all authentication checks.", "High"),
    ("block_timestamp", "Block Timestamp Dependency", "block.timestamp used in critical logic.", "Allow ~15 second tolerance; do not rely on exact timestamp values.", "Medium"),
    ("delegatecall", "Delegatecall Usage", "delegatecall detected - storage layout must match the target contract.", "Ensure the target is trusted and storage layouts are perfectly aligned.", "High"),
    ("assert_usage", "Assert Instead of Require", "assert() used where require() is more appropriate.", "Use require() for input validation; reserve assert() for internal invariants.", "Low"),
    ("unbounded_loop", "Unbounded Loop", "Loop without an upper bound - potential DoS vector.", "Add explicit loop limits or use pagination patterns.", "Medium"),
    ("hardcoded_address", "Hardcoded Address", "An Ethereum address is hardcoded in the contract.", "Use configurable addresses set via constructor or owner-controlled setter.", "Low"),
    ("frontrunning", "Frontrunning Vulnerability", "Potential frontrunning vulnerability pattern detected.", "Use a commit-reveal scheme or Flashbots bundles.", "Medium"),
    ("assembly_storage", "Assembly Storage Manipulation", "Inline assembly accesses storage directly.", "Review assembly carefully; prefer high-level Solidity where possible.", "High"),
    ("dos_external_calls", "DoS via External Calls", "Potential Denial-of-Service through unchecked external calls.", "Implement the pull-over-push payment pattern.", "Medium"),
    ("unchecked_call_returns", "Unchecked Call Return Value", "Return value of low-level .call() is not checked.", "Always check and handle the return value of .call().", "High"),
    ("weak_randomness", "Weak Randomness Source", "On-chain randomness derived from blockhash / timestamp / block.number.", "Use Chainlink VRF or a commit-reveal scheme for randomness.", "High"),
    ("flash_loan", "Flash Loan Risk", "Potential flash loan vulnerability (transferFrom with msg.sender).", "Add flash loan protection (e.g., check balances before and after the call).", "Critical"),
    ("oracle_manipulation", "Oracle Manipulation Risk", "Price oracle function detected without TWAP protection.", "Use a Time-Weighted Average Price (TWAP) from a reputable oracle.", "High"),
    ("reentrancy", "Reentrancy Risk", "Potential reentrancy via .call / .transfer / .send.", "Follow checks-effects-interactions and use OpenZeppelin ReentrancyGuard.", "High"),
    ("unsafe_math", "Unsafe Arithmetic", "Arithmetic without SafeMath or unchecked block.", "Use Solidity >= 0.8 built-in overflow checks, or SafeMath library.", "Medium"),
    # ── Расширенные проверки ──────────────────────────────────────────────────
    ("selfdestruct",            "Unprotected selfdestruct",          "selfdestruct() detected — verify it is restricted to owner.", "Restrict with onlyOwner or remove entirely (deprecated EIP-6049).", "Critical"),
    ("initialize_unprotected",  "Unprotected initialize()",          "initialize() function found — verify it uses the initializer modifier.", "Use OpenZeppelin Initializable with initializer modifier.", "Critical"),
    ("ecrecover",               "ecrecover Usage",                   "Raw ecrecover() detected — vulnerable to zero-address and malleability.", "Use OpenZeppelin ECDSA library.", "High"),
    ("approve_race",            "ERC-20 approve() Race Condition",   "approve() with non-zero value — race condition possible.", "Use safeIncreaseAllowance or reset to 0 first.", "Medium"),
    ("abi_encode_packed",       "abi.encodePacked Hash Collision",   "abi.encodePacked with potentially dynamic arguments.", "Use abi.encode() to avoid hash collisions.", "Medium"),
    ("signature_replay",        "Signature Replay Risk",             "ecrecover without visible nonce — replay attack possible.", "Include nonce + chainId in signed message (EIP-712).", "High"),
    ("price_manipulation",      "AMM Spot Price Manipulation",       "Direct AMM reserve read detected — flash loan manipulation possible.", "Use TWAP oracle or Chainlink price feed.", "Critical"),
    ("unchecked_block",         "unchecked Block Usage",             "unchecked{} disables overflow protection.", "Only use unchecked when overflow is mathematically impossible.", "Medium"),
    ("silent_overflow",         "Silent Overflow in unchecked",      "Arithmetic increment/decrement inside unchecked block.", "Verify bounds before unchecked scope.", "High"),
    ("erc20_unchecked",         "Unchecked ERC-20 Return Value",     "ERC-20 transfer/transferFrom return value may be ignored.", "Use OpenZeppelin SafeERC20 (safeTransfer, safeTransferFrom).", "High"),
    ("eth_transfer_old",        "payable.transfer() Gas Limit",      "payable.transfer() uses fixed 2300 gas — breaks with contract recipients.", "Replace with call{value:} and check return value.", "Medium"),
    ("block_number_time",       "block.number Used as Time",         "block.number is not a reliable time source across chains.", "Use block.timestamp with tolerance or a dedicated oracle.", "Low"),
    ("open_receive",            "Unrestricted receive() Function",   "receive() is payable — verify intentional ETH acceptance.", "Add access control or event logging if ETH receipt is not intended.", "Low"),
    ("integer_division",        "Integer Division Precision Loss",   "Integer division truncates — possible precision loss.", "Multiply before dividing, or use fixed-point math library.", "Low"),
    ("ownership_transfer",      "Ownership Transfer Without 2-Step", "transferOwnership() detected — single-step transfer risks losing ownership.", "Use Ownable2Step (OpenZeppelin) for two-step ownership transfer.", "Medium"),
    ("msg_value_loop",          "msg.value Inside Loop",             "msg.value used inside a loop — each iteration reuses the same value.", "Cache msg.value before the loop and validate carefully.", "Critical"),
]


# ─────────────────────────────────────────────────────────────────────────────
#  UTILITY FUNCTIONS
# ─────────────────────────────────────────────────────────────────────────────

def save_to_temp(source: str) -> str:
    h = hashlib.sha256(source.encode()).hexdigest()[:8]
    path = os.path.join(TEMP_DIR, f"contract_{h}.sol")
    with open(path, "w", encoding="utf-8") as f:
        f.write(source)
    os.chmod(path, 0o600)
    logger.info("Contract saved to: %s", path)
    return path


# ─────────────────────────────────────────────────────────────────────────────
#  AUTO-UPDATE TOOLS
# ─────────────────────────────────────────────────────────────────────────────

PIP_TOOLS: dict[str, str] = {
    "slither": "slither-analyzer",
    "myth":    "mythril",
    "halmos":  "halmos",
}

TOOL_VERSION_CMDS: dict[str, list[str]] = {
    "slither": ["slither", "--version"],
    "myth":    ["myth", "version"],
    "echidna": ["echidna", "--version"],
    "medusa":  ["medusa", "--version"],
    "halmos":  ["halmos", "--version"],
    "solc":    ["solc", "--version"],
}

# ─────────────────────────────────────────────────────────────────────────────
#  VERSION LOCK
#  Путь к файлу фиксации версий. Лежит рядом со скриптом.
#  Формат JSON: { "slither": "0.10.1", "myth": "0.24.7", ... }
#  Если версия в lock-файле совпадает с установленной — обновление пропускается,
#  что гарантирует одинаковые результаты при каждом запуске.
# ─────────────────────────────────────────────────────────────────────────────

LOCK_FILE = os.path.join(os.path.dirname(os.path.abspath(sys.argv[0])), "tool_versions.lock")


def _load_lock() -> dict[str, str]:
    """Загрузить зафиксированные версии из lock-файла."""
    if os.path.isfile(LOCK_FILE):
        try:
            with open(LOCK_FILE, "r", encoding="utf-8") as fp:
                return json.load(fp)
        except Exception:
            pass
    return {}


def _save_lock(locked: dict[str, str]) -> None:
    """Сохранить текущие версии инструментов в lock-файл."""
    try:
        with open(LOCK_FILE, "w", encoding="utf-8") as fp:
            json.dump(locked, fp, indent=2, ensure_ascii=False)
        _print(f"  Version lock saved: {LOCK_FILE}", "dim")
        logger.info("tool_versions.lock updated: %s", locked)
    except Exception as exc:
        _print(f"  Warning: could not write lock file: {exc}", "yellow")
        logger.warning("Could not write lock file: %s", exc)


def _parse_version(text: str) -> Optional[tuple[int, ...]]:
    m = re.search(r'(\d+)\.(\d+)\.(\d+)', text)
    return tuple(int(x) for x in m.groups()) if m else None


def _version_str(t: Optional[tuple[int, ...]]) -> str:
    return ".".join(str(x) for x in t) if t else "?"


def _get_latest_pip_version(package: str) -> Optional[tuple[int, ...]]:
    try:
        import urllib.request, json as _json
        url  = f"https://pypi.org/pypi/{package}/json"
        with urllib.request.urlopen(url, timeout=10) as resp:
            data = _json.loads(resp.read())
        return _parse_version(data["info"]["version"])
    except Exception:
        return None


def _get_latest_solc_version() -> Optional[tuple[int, ...]]:
    try:
        import urllib.request, json as _json
        url = "https://binaries.soliditylang.org/linux-amd64/list.json"
        with urllib.request.urlopen(url, timeout=10) as resp:
            data = _json.loads(resp.read())
        latest = data.get("latestRelease", "")
        return _parse_version(latest)
    except Exception:
        return None


def _update_pip_tool(binary: str, package: str) -> bool:
    _print(f"  Updating {binary} ({package})...", "cyan")
    code, _, stderr = run_tool(
        [sys.executable, "-m", "pip", "install", "--upgrade", "--quiet", package],
        timeout=120,
    )
    if code == 0:
        _print(f"  {binary} updated successfully.", "green")
        logger.info("Updated pip tool: %s (%s)", binary, package)
        return True
    else:
        _print(f"  Failed to update {binary}: {stderr.strip()}", "red")
        logger.warning("Failed to update %s: %s", binary, stderr)
        return False


def _update_solc() -> bool:
    if shutil.which("solc-select"):
        _print("  Updating solc via solc-select...", "cyan")
        latest = _get_latest_solc_version()
        if latest:
            ver_str = _version_str(latest)
            code, _, stderr = run_tool(
                ["solc-select", "install", ver_str], timeout=120
            )
            if code == 0:
                run_tool(["solc-select", "use", ver_str], timeout=15)
                _print(f"  solc updated to {ver_str}.", "green")
                logger.info("Updated solc to %s via solc-select", ver_str)
                return True
            else:
                _print(f"  solc-select install failed: {stderr.strip()}", "red")
    else:
        _print("  Updating solc via pip (py-solc-x)...", "cyan")
        try:
            code, _, _ = run_tool(
                [sys.executable, "-m", "pip", "install", "--upgrade", "--quiet", "py-solc-x"],
                timeout=60,
            )
            if code == 0:
                code2, _, _ = run_tool(
                    [sys.executable, "-c", "from solcx import install_solc; install_solc('latest')"],
                    timeout=120,
                )
                if code2 == 0:
                    _print("  solc updated via py-solc-x.", "green")
                    logger.info("Updated solc via py-solc-x")
                    return True
        except Exception:
            pass
        _print("  Cannot auto-update solc. Install solc-select: pip install solc-select", "yellow")
    return False


def auto_update_tools() -> None:
    _print("Checking tools for updates...", "cyan")

    # ── Загружаем lock-файл с зафиксированными версиями ──────────────────────────────────
    locked   = _load_lock()        # { binary: "x.y.z" }  — то, что уже зафиксировано
    new_lock = dict(locked)        # будем обновлять и сохраним в конце

    if locked:
        _print(f"  Found version lock: {LOCK_FILE}", "dim")
    else:
        _print("  No version lock found — will create one after this run.", "dim")

    for binary, version_cmd in TOOL_VERSION_CMDS.items():
        if not shutil.which(version_cmd[0]):
            _print(f"  {binary}: not installed — skipping.", "yellow")
            continue

        _, stdout, stderr = run_tool(version_cmd, timeout=15)
        current     = _parse_version((stdout + " " + stderr).strip())
        current_str = _version_str(current)

        # ── Проверяем: версия уже зафиксирована? ─────────────────────────────────────────
        if binary in locked:
            if current_str == locked[binary]:
                _print(
                    f"  {binary} {current_str} — locked ✓ (обновление пропущено, версия зафиксирована)",
                    "green",
                )
                logger.info("Skipped update for %s — version locked at %s", binary, current_str)
                continue
            else:
                # Версия изменилась относительно lock-файла — предупреждаем и перефиксируем
                _print(
                    f"  {binary}: installed version {current_str} differs from locked {locked[binary]}. "
                    "Re-locking to installed version — update skipped.",
                    "yellow",
                )
                logger.warning(
                    "%s version mismatch: locked=%s installed=%s — re-locking",
                    binary, locked[binary], current_str,
                )
                new_lock[binary] = current_str
                continue

        # ── Версия ещё не зафиксирована — выполняем стандартную проверку/обновление ──
        if binary in PIP_TOOLS:
            package = PIP_TOOLS[binary]
            latest  = _get_latest_pip_version(package)
            if latest is None:
                _print(f"  {binary}: could not fetch latest version from PyPI.", "yellow")
                if current:
                    new_lock[binary] = current_str
                continue
            if current and current >= latest:
                _print(f"  {binary} {current_str} is up to date.", "green")
                new_lock[binary] = current_str
            else:
                old = current_str if current else "unknown"
                _print(f"  {binary}: {old} → {_version_str(latest)}. Updating...", "yellow")
                if _update_pip_tool(binary, package):
                    # Перечитываем версию после обновления
                    _, so2, se2 = run_tool(version_cmd, timeout=15)
                    updated = _parse_version((so2 + " " + se2).strip())
                    new_lock[binary] = _version_str(updated) if updated else _version_str(latest)
                else:
                    if current:
                        new_lock[binary] = current_str

        elif binary == "solc":
            latest = _get_latest_solc_version()
            if latest is None:
                _print("  solc: could not fetch latest version.", "yellow")
                if current:
                    new_lock[binary] = current_str
                continue
            if current and current >= latest:
                _print(f"  solc {current_str} is up to date.", "green")
                new_lock[binary] = current_str
            else:
                old = current_str if current else "unknown"
                _print(f"  solc: {old} → {_version_str(latest)}. Updating...", "yellow")
                if _update_solc():
                    new_lock[binary] = _version_str(latest)
                else:
                    if current:
                        new_lock[binary] = current_str

        else:
            # Бинарные инструменты (echidna, medusa) — только фиксируем текущую версию
            ver = current_str if current else "unknown"
            _print(f"  {binary} {ver} (binary install — auto-update not supported)", "dim")
            if current:
                new_lock[binary] = current_str

    # ── Сохраняем обновлённый lock-файл ────────────────────────────────────────────
    if new_lock != locked:
        _save_lock(new_lock)

    _print("Tool update check complete.\n", "cyan")

# ─────────────────────────────────────────────────────────────────────────────
#  PROJECT DETECTION  —  single file | Foundry | Hardhat
# ─────────────────────────────────────────────────────────────────────────────

class ProjectType:
    SINGLE_FILE = "single_file"
    FOUNDRY     = "foundry"
    HARDHAT     = "hardhat"


def detect_project(path: str) -> tuple[str, str]:
    """
    Given a path (file or directory) return (project_type, project_root).

    Detection rules:
      - If path is a .sol file → SINGLE_FILE, root = parent dir
      - If directory contains foundry.toml        → FOUNDRY
      - If directory contains hardhat.config.*    → HARDHAT
      - If directory contains package.json + contracts/ → HARDHAT (fallback)
      - Otherwise walk up the tree looking for the same markers
    """
    if os.path.isfile(path):
        if path.endswith(".sol"):
            return ProjectType.SINGLE_FILE, os.path.dirname(os.path.abspath(path))
        _print(f"Unsupported file type: {path}", "red")
        sys.exit(1)

    root = os.path.abspath(path)

    # Walk from root upward (max 4 levels) to find project markers
    check = root
    for _ in range(5):
        if os.path.isfile(os.path.join(check, "foundry.toml")):
            return ProjectType.FOUNDRY, check
        hh = (
            os.path.isfile(os.path.join(check, "hardhat.config.js")) or
            os.path.isfile(os.path.join(check, "hardhat.config.ts"))
        )
        if hh:
            return ProjectType.HARDHAT, check
        # package.json + contracts/ dir = likely Hardhat
        if (os.path.isfile(os.path.join(check, "package.json")) and
                os.path.isdir(os.path.join(check, "contracts"))):
            return ProjectType.HARDHAT, check
        parent = os.path.dirname(check)
        if parent == check:
            break
        check = parent

    # Directory but no known marker → treat as single-file directory
    # and look for any .sol file inside
    sol_files = []
    for dirpath, _, filenames in os.walk(root):
        for fn in filenames:
            if fn.endswith(".sol"):
                sol_files.append(os.path.join(dirpath, fn))
    if sol_files:
        _print(
            f"No foundry.toml / hardhat.config found. "
            f"Found {len(sol_files)} .sol file(s) — treating as flat directory.",
            "yellow",
        )
        return ProjectType.SINGLE_FILE, root

    _print(f"No Solidity files found in: {root}", "red")
    sys.exit(1)


def _collect_sol_sources(project_root: str, project_type: str) -> tuple[list[str], str]:
    """
    Return (list_of_sol_paths, representative_main_path).
    For SINGLE_FILE root: all .sol files in the directory.
    For FOUNDRY: src/ + script/ folders.
    For HARDHAT: contracts/ folder.
    """
    if project_type == ProjectType.FOUNDRY:
        search_dirs = [
            os.path.join(project_root, "src"),
            os.path.join(project_root, "script"),
        ]
    elif project_type == ProjectType.HARDHAT:
        search_dirs = [
            os.path.join(project_root, "contracts"),
            os.path.join(project_root, "src"),
        ]
    else:
        search_dirs = [project_root]

    sol_files = []
    for d in search_dirs:
        if not os.path.isdir(d):
            continue
        for dirpath, _, filenames in os.walk(d):
            # Skip node_modules, lib, cache, out
            skip = {"node_modules", "lib", "cache", "out", "artifacts", ".git"}
            if any(s in dirpath.split(os.sep) for s in skip):
                continue
            for fn in filenames:
                if fn.endswith(".sol"):
                    sol_files.append(os.path.join(dirpath, fn))

    if not sol_files:
        # Fallback: scan everywhere
        for dirpath, _, filenames in os.walk(project_root):
            skip = {"node_modules", "lib", "cache", "out", "artifacts", ".git"}
            if any(s in dirpath.split(os.sep) for s in skip):
                continue
            for fn in filenames:
                if fn.endswith(".sol"):
                    sol_files.append(os.path.join(dirpath, fn))

    main_path = sol_files[0] if sol_files else project_root
    return sol_files, main_path


def _read_combined_source(sol_files: list[str]) -> str:
    """Read and concatenate all .sol files (used for static/AST analysis)."""
    parts = []
    for fp in sol_files:
        try:
            with open(fp, encoding="utf-8") as f:
                parts.append(f"// ═══ {os.path.basename(fp)} ═══\n" + f.read())
        except OSError:
            pass
    return "\n\n".join(parts)


# ─────────────────────────────────────────────────────────────────────────────
#  FOUNDRY SUPPORT
# ─────────────────────────────────────────────────────────────────────────────

def run_foundry_build(project_root: str) -> list[dict]:
    """
    Run `forge build` and surface compiler errors/warnings as findings.
    Returns list of findings (errors = Critical, warnings = Low).
    """
    if not shutil.which("forge"):
        _print("Forge not found — skipping Foundry build. (Install: https://getfoundry.sh)", "yellow")
        return []

    _print("Running forge build...", "cyan")
    code, stdout, stderr = run_tool(
        ["forge", "build", "--root", project_root], timeout=300
    )

    findings = []
    combined = (stdout or "") + (stderr or "")

    # Compiler errors: "Error (XXXX): message\n  --> path:line:col"
    err_re  = re.compile(r"(Error|Warning)\s*(?:\(\d+\))?:\s*(.+?)(?=\n\s*-->|\n\s*\n|\Z)", re.DOTALL)
    loc_re  = re.compile(r"-->\s*(.+?):(\d+):\d+")

    for m in err_re.finditer(combined):
        kind    = m.group(1)
        msg     = m.group(2).strip().replace("\n", " ")
        # Find nearest location hint
        loc_m   = loc_re.search(combined, m.end())
        loc_str = f"{loc_m.group(1)}:{loc_m.group(2)}" if loc_m else "forge build output"
        findings.append({
            "type":           f"forge_{kind.lower()}",
            "severity":       "Critical" if kind == "Error" else "Low",
            "description":    f"forge build {kind}: {msg}",
            "location":       loc_str,
            "recommendation": "Fix the compiler error before running security analysis.",
            "tool":           "Foundry",
            "swc_id":         "N/A",
        })

    if code == 0 and not findings:
        _print("forge build: success ✓", "green")
    else:
        _print(f"forge build: {len(findings)} issue(s).", "yellow" if findings else "green")

    return findings


def run_foundry_tests(project_root: str) -> list[dict]:
    """
    Run `forge test -vv` and parse failing tests as findings.
    Each FAIL becomes a High finding; each PASS is silently ignored.
    """
    if not shutil.which("forge"):
        return []

    _print("Running forge test...", "cyan")
    code, stdout, stderr = run_tool(
        ["forge", "test", "--root", project_root, "-vv", "--no-match-test", "invariant"],
        timeout=600,
    )

    findings = []
    combined = (stdout or "") + (stderr or "")

    # forge test output lines: "[FAIL] testName() (reason: ...)"
    fail_re = re.compile(
        r"\[FAIL\]\s+([\w:]+)\s*(?:\(([^)]*)\))?", re.IGNORECASE
    )
    for m in fail_re.finditer(combined):
        test_name = m.group(1)
        reason    = m.group(2) or "See forge test output for counterexample"
        findings.append({
            "type":           "forge_test_fail",
            "severity":       "High",
            "description":    f"Forge test FAILED: {test_name}. Reason: {reason}",
            "location":       f"Test: {test_name}",
            "recommendation": (
                "Investigate the failing test — it may indicate a real vulnerability. "
                "Run `forge test -vvvv` for full trace."
            ),
            "tool":           "Foundry",
            "swc_id":         "N/A",
        })

    # Invariant failures
    inv_re = re.compile(r"invariant_\w+\s+FAILED", re.IGNORECASE)
    for m in inv_re.finditer(combined):
        findings.append({
            "type":           "forge_invariant_fail",
            "severity":       "Critical",
            "description":    f"Forge invariant test FAILED: {m.group(0).strip()}",
            "location":       "Invariant test suite",
            "recommendation": (
                "A broken invariant often means a critical vulnerability. "
                "Run `forge test --match-test invariant -vvvv` for full trace."
            ),
            "tool":           "Foundry",
            "swc_id":         "N/A",
        })

    passed  = len(re.findall(r"\[PASS\]", combined))
    _print(
        f"forge test: {passed} passed, {len(findings)} failed.",
        "green" if not findings else "red",
    )
    return findings


def run_foundry_coverage(project_root: str) -> dict:
    """
    Run `forge coverage --summary` and return coverage metrics dict.
    Returns {} if forge is not installed or coverage fails.
    """
    if not shutil.which("forge"):
        return {}

    _print("Running forge coverage (summary)...", "cyan")
    code, stdout, _ = run_tool(
        ["forge", "coverage", "--root", project_root, "--report", "summary"],
        timeout=300,
    )
    if code != 0 or not stdout:
        return {}

    metrics: dict = {"lines": None, "branches": None, "functions": None}
    # Lines: "| File | % Lines | % Statements | % Branches | % Funcs |"
    cov_re = re.compile(
        r"Totals?\s*\|\s*([\d.]+)%\s*\|\s*([\d.]+)%\s*\|\s*([\d.]+)%\s*\|\s*([\d.]+)%"
    )
    m = cov_re.search(stdout)
    if m:
        metrics = {
            "lines":      float(m.group(1)),
            "statements": float(m.group(2)),
            "branches":   float(m.group(3)),
            "functions":  float(m.group(4)),
        }
        _print(
            f"forge coverage: Lines {metrics['lines']}% | "
            f"Branches {metrics['branches']}% | "
            f"Functions {metrics['functions']}%",
            "cyan",
        )
    return metrics


# ─────────────────────────────────────────────────────────────────────────────
#  HARDHAT SUPPORT
# ─────────────────────────────────────────────────────────────────────────────

def _npm_cmd(project_root: str) -> list[str]:
    """Return ['npx'] or ['yarn'] depending on which lockfile is present."""
    if os.path.isfile(os.path.join(project_root, "yarn.lock")):
        return ["yarn"]
    return ["npx", "--yes"]


def run_hardhat_compile(project_root: str) -> list[dict]:
    """Run `npx hardhat compile` and surface errors as findings."""
    npx = _npm_cmd(project_root)
    cmd = npx + ["hardhat", "compile", "--config",
                 _hh_config(project_root)]
    _print("Running hardhat compile...", "cyan")
    code, stdout, stderr = run_tool(cmd, timeout=300, cwd=project_root)

    findings = []
    combined = (stdout or "") + (stderr or "")

    err_re = re.compile(r"Error\s+(?:HH\d+\s*)?:\s*(.+?)(?=\n|\Z)")
    for m in err_re.finditer(combined):
        findings.append({
            "type":           "hardhat_compile_error",
            "severity":       "Critical",
            "description":    f"Hardhat compile error: {m.group(1).strip()}",
            "location":       "hardhat compile output",
            "recommendation": "Fix the compiler error before running security analysis.",
            "tool":           "Hardhat",
            "swc_id":         "N/A",
        })

    if code == 0:
        _print("hardhat compile: success ✓", "green")
    else:
        _print(f"hardhat compile: {len(findings)} error(s).", "red")

    return findings


def run_hardhat_tests(project_root: str) -> list[dict]:
    """Run `npx hardhat test` and parse failures."""
    npx = _npm_cmd(project_root)
    cmd = npx + ["hardhat", "test", "--config", _hh_config(project_root)]
    _print("Running hardhat test...", "cyan")
    code, stdout, stderr = run_tool(cmd, timeout=600, cwd=project_root)

    findings = []
    combined = (stdout or "") + (stderr or "")

    # Mocha output: "  N failing" followed by "  N) test name"
    fail_re = re.compile(r"^\s+\d+\)\s+(.+)$", re.MULTILINE)
    reason_re = re.compile(r"AssertionError:\s*(.+)|Error:\s*(.+)")
    for m in fail_re.finditer(combined):
        test_name = m.group(1).strip()
        reason_m  = reason_re.search(combined[m.end():m.end()+400])
        reason    = reason_m.group(1) or reason_m.group(2) if reason_m else "See test output"
        findings.append({
            "type":           "hardhat_test_fail",
            "severity":       "High",
            "description":    f"Hardhat test FAILED: {test_name}. {reason.strip()}",
            "location":       f"Test: {test_name}",
            "recommendation": (
                "Investigate the failing test — it likely exposes a real bug. "
                "Run `npx hardhat test --grep \"<test name>\"` for details."
            ),
            "tool":           "Hardhat",
            "swc_id":         "N/A",
        })

    passed = len(re.findall(r"passing", combined))
    _print(
        f"hardhat test: {passed} suite(s) passing, {len(findings)} failing.",
        "green" if not findings else "red",
    )
    return findings


def _hh_config(project_root: str) -> str:
    """Return path to hardhat config file."""
    for name in ("hardhat.config.ts", "hardhat.config.js"):
        p = os.path.join(project_root, name)
        if os.path.isfile(p):
            return p
    return "hardhat.config.js"


# ─────────────────────────────────────────────────────────────────────────────
#  PATCH run_tool to accept optional cwd parameter
# ─────────────────────────────────────────────────────────────────────────────

def run_tool(cmd: list[str], timeout: int = 300, cwd: str = None) -> tuple[int, str, str]:
    try:
        r = subprocess.run(
            cmd, capture_output=True, text=True,
            timeout=timeout, cwd=cwd,
        )
        return r.returncode, r.stdout, r.stderr
    except subprocess.TimeoutExpired:
        return -1, "", f"Timeout after {timeout}s"
    except FileNotFoundError:
        return -2, "", f"Command not found: {cmd[0]}"
    except Exception as e:
        return -3, "", str(e)


# ─────────────────────────────────────────────────────────────────────────────
#  IMPROVED STATIC ANALYSIS  — strips comments before regex
# ─────────────────────────────────────────────────────────────────────────────

def _strip_comments(source: str) -> str:
    """
    Remove Solidity single-line (//) and multi-line (/* */) comments.
    Preserves line numbers so 'Line N' locations stay correct.
    """
    # Replace block comments with whitespace (keep newlines)
    def _replace_block(m):
        return re.sub(r"[^\n]", " ", m.group(0))

    source = re.sub(r"/\*.*?\*/", _replace_block, source, flags=re.DOTALL)
    # Replace line comments with empty to EOL
    source = re.sub(r"//[^\n]*", lambda m: " " * len(m.group(0)), source)
    return source


# ─────────────────────────────────────────────────────────────────────────────
#  ANALYZERS
# ─────────────────────────────────────────────────────────────────────────────

def run_slither(contract_path: str) -> list[dict]:
    if not shutil.which("slither"):
        _print("Slither not found - skipping. (pip install slither-analyzer)", "yellow")
        return []
    _print("Running Slither...", "cyan")
    code, stdout, stderr = run_tool(["slither", contract_path, "--json", "-", "--checklist"], timeout=300)
    if code == -1:
        _print(f"Slither timed out. {stderr}", "yellow")
        return []
    findings = []
    try:
        data = json.loads(stdout)
        sev_map = {"High": "High", "Medium": "Medium", "Low": "Low", "Informational": "Low"}
        for det in data.get("results", {}).get("detectors", []):
            findings.append({
                "type": det.get("check", "unknown"),
                "severity": sev_map.get(det.get("impact", "Medium"), "Medium"),
                "description": det.get("description", "").strip(),
                "location": det.get("first_markdown_element", "N/A"),
                "recommendation": det.get("recommendation", "Review manually.").strip(),
                "tool": "Slither",
                "swc_id": SWC_IDS.get(det.get("check", ""), "N/A"),
            })
    except Exception:
        logger.warning("Slither JSON parse error")
    _print(f"Slither: {len(findings)} finding(s).", "green")
    return findings


def run_mythril(contract_path: str) -> list[dict]:
    if not shutil.which("myth"):
        _print("Mythril not found - skipping. (pip install mythril)", "yellow")
        return []
    _print("Running Mythril...", "cyan")
    code, stdout, stderr = run_tool(["myth", "analyze", contract_path, "-o", "json"], timeout=600)
    findings = []
    try:
        data = json.loads(stdout)
        sev_map = {"High": "High", "Medium": "Medium", "Low": "Low"}
        for issue in data.get("issues", []):
            findings.append({
                "type": issue.get("title", "unknown"),
                "severity": sev_map.get(issue.get("severity", "Medium"), "Medium"),
                "description": issue.get("description", "").strip(),
                "location": f"Line {issue.get('lineno', 'N/A')}",
                "recommendation": "Review the flagged code segment.",
                "tool": "Mythril",
                "swc_id": issue.get("swc-id", "N/A"),
            })
    except Exception:
        logger.warning("Mythril JSON parse error")
    _print(f"Mythril: {len(findings)} finding(s).", "green")
    return findings



# ─────────────────────────────────────────────────────────────────────────────
#  АВТОГЕНЕРАЦИЯ ТЕСТ-КОНТРАКТА для Echidna / Medusa / Halmos
#  Анализирует любой контракт клиента и создаёт wrapper с тест-функциями.
#  Тесты охватывают: балансы, переполнение, доступ, ETH, паузы, supply.
# ─────────────────────────────────────────────────────────────────────────────

def _extract_contract_info(source: str) -> dict:
    """
    Парсит исходник контракта и извлекает:
    - имя основного контракта
    - публичные функции с их аргументами
    - state variables (mapping балансов, totalSupply, owner, paused и т.д.)
    - pragma версию
    """
    info = {
        "contract_name":   None,
        "pragma":          "^0.8.0",
        "has_balances":    False,
        "has_total_supply":False,
        "has_owner":       False,
        "has_paused":      False,
        "has_mint":        False,
        "has_burn":        False,
        "has_transfer":    False,
        "has_withdraw":    False,
        "has_deposit":     False,
        "has_approve":     False,
        "has_erc20":       False,
        "has_erc721":      False,
        "has_receive_eth": False,
        "has_unchecked":   False,
        "state_vars":      [],
        "public_funcs":    [],
    }

    # pragma
    pm = re.search(r"pragma\s+solidity\s+([^;]+);", source)
    if pm:
        info["pragma"] = pm.group(1).strip()

    # основной контракт — берём последний (обычно он главный)
    contracts = re.findall(r"contract\s+(\w+)", source)
    if contracts:
        info["contract_name"] = contracts[-1]

    src_lower = source.lower()

    # что есть в контракте
    info["has_balances"]     = bool(re.search(r"balances\s*\[|_balances\s*\[|balance\s*\[", source))
    info["has_total_supply"] = bool(re.search(r"totalSupply|_totalSupply|total_supply", source))
    info["has_owner"]        = bool(re.search(r"owner|onlyOwner", source))
    info["has_paused"]       = bool(re.search(r"paused|pause|unpause", source))
    info["has_mint"]         = bool(re.search(r"function\s+mint", source))
    info["has_burn"]         = bool(re.search(r"function\s+burn", source))
    info["has_transfer"]     = bool(re.search(r"function\s+transfer", source))
    info["has_withdraw"]     = bool(re.search(r"function\s+withdraw", source))
    info["has_deposit"]      = bool(re.search(r"function\s+deposit", source))
    info["has_approve"]      = bool(re.search(r"function\s+approve", source))
    info["has_erc20"]        = bool(re.search(r"IERC20|ERC20|balanceOf|transferFrom", source))
    info["has_erc721"]       = bool(re.search(r"IERC721|ERC721|ownerOf|safeTransferFrom", source))
    info["has_receive_eth"]  = bool(re.search(r"receive\s*\(\s*\)\s*external\s+payable|msg\.value", source))
    info["has_unchecked"]    = bool(re.search(r"\bunchecked\b", source))

    # публичные функции (для fuzzing)
    for m in re.finditer(
        r"function\s+(\w+)\s*\(([^)]*)\)\s*(?:public|external)",
        source
    ):
        fname  = m.group(1)
        fargs  = m.group(2).strip()
        # пропускаем конструкторы, view/pure, геттеры
        if fname in ("constructor", "receive", "fallback"):
            continue
        if re.search(r"\bview\b|\bpure\b", source[m.start():m.start()+200]):
            continue
        info["public_funcs"].append({"name": fname, "args": fargs})

    return info


def _generate_test_contract(source: str, info: dict, tool: str) -> str:
    """
    Генерирует Solidity тест-контракт который наследует оригинальный контракт
    и добавляет тест-функции для указанного инструмента.
    tool: "echidna" | "medusa" | "halmos"
    """
    cname  = info["contract_name"] or "Contract"
    pragma = info["pragma"]

    if tool == "echidna":
        prefix = "echidna_"
        ret    = "public returns (bool)"
    elif tool == "medusa":
        prefix = "property_"
        ret    = "public returns (bool)"
    else:  # halmos
        prefix = "check_"
        ret    = "public"

    def bool_test(fname, body_lines):
        body = "\n".join("        " + l for l in body_lines)
        return (
            "    function " + prefix + fname + "() " + ret + " {\n"
            + body + "\n"
            + "    }\n"
        )

    def assert_test(fname, body_lines):
        body = "\n".join("        " + l for l in body_lines)
        return (
            "    function " + prefix + fname + "() " + ret + " {\n"
            + body + "\n"
            + "    }\n"
        )

    def make(fname, bool_body, assert_body):
        if tool == "halmos":
            return assert_test(fname, assert_body)
        else:
            return bool_test(fname, bool_body)

    tests = []

    # 1. ERC-20: баланс не отрицательный
    if info["has_erc20"] or info["has_balances"]:
        tests.append(make(
            "balance_not_negative",
            ["return balanceOf(address(this)) >= 0;"],
            ["assert(balanceOf(address(this)) >= 0);"],
        ))

    # 2. totalSupply >= баланс любого адреса
    if info["has_total_supply"] and info["has_balances"]:
        tests.append(make(
            "total_supply_gte_balance",
            ["return totalSupply() >= balanceOf(address(this));"],
            ["assert(totalSupply() >= balanceOf(address(this)));"],
        ))

    # 3. transfer не создаёт токены из воздуха
    if info["has_transfer"] and info["has_total_supply"]:
        tests.append(make(
            "transfer_preserves_supply",
            [
                "uint256 before = totalSupply();",
                "try this.transfer(address(0x1), 1) {} catch {}",
                "return totalSupply() == before;",
            ],
            [
                "uint256 before = totalSupply();",
                "assert(totalSupply() == before);",
            ],
        ))

    # 4. mint увеличивает totalSupply
    if info["has_mint"] and info["has_total_supply"]:
        tests.append(make(
            "mint_increases_supply",
            [
                "uint256 before = totalSupply();",
                "try this.mint(address(this), 1) {}",
                "catch {}",
                "return totalSupply() >= before;",
            ],
            [
                "uint256 before = totalSupply();",
                "mint(address(this), 1e18);",
                "assert(totalSupply() > before);",
            ],
        ))

    # 5. burn уменьшает totalSupply
    if info["has_burn"] and info["has_total_supply"]:
        tests.append(make(
            "burn_decreases_supply",
            [
                "uint256 before = totalSupply();",
                "if (before == 0) return true;",
                "try this.burn(1) {} catch {}",
                "return totalSupply() <= before;",
            ],
            [
                "uint256 before = totalSupply();",
                "if (before == 0) return;",
                "burn(1);",
                "assert(totalSupply() < before);",
            ],
        ))

    # 6. ETH баланс контракта >= 0
    if info["has_receive_eth"] or info["has_withdraw"] or info["has_deposit"]:
        tests.append(make(
            "eth_balance_non_negative",
            ["return address(this).balance >= 0;"],
            ["assert(address(this).balance >= 0);"],
        ))

    # 7. withdraw не даёт больше чем есть
    if info["has_withdraw"] and info["has_deposit"]:
        tests.append(make(
            "no_free_eth_withdraw",
            [
                "uint256 before = address(this).balance;",
                "try this.withdraw() {} catch {}",
                "return address(this).balance >= 0;",
            ],
            [
                "uint256 contractBal = address(this).balance;",
                "assert(contractBal >= 0);",
            ],
        ))

    # 8. paused блокирует transfer
    if info["has_paused"] and info["has_transfer"]:
        tests.append(make(
            "paused_blocks_transfer",
            [
                "if (!paused()) return true;",
                "try this.transfer(address(0x1), 1) {",
                "    return false;",
                "} catch {",
                "    return true;",
                "}",
            ],
            [
                "assert(true);",
            ],
        ))

    # 9. no overflow в unchecked блоках
    if info["has_unchecked"] or tool == "halmos":
        tests.append(make(
            "no_overflow_uint256",
            ["return type(uint256).max > 0;"],
            [
                "uint256 a = type(uint256).max / 2;",
                "uint256 b = type(uint256).max / 2;",
                "assert(a + b >= a);",
            ],
        ))

    # 10. approve не создаёт allowance из воздуха
    if info["has_approve"] and info["has_erc20"]:
        tests.append(make(
            "approve_allowance_bounded",
            [
                "try this.approve(address(0x1), 0) {} catch {}",
                "return allowance(address(this), address(0x1)) == 0;",
            ],
            [
                "assert(allowance(address(this), address(0x1)) == 0);",
            ],
        ))

    # Универсальный тест если контракт непонятен
    if not tests:
        tests.append(make(
            "contract_deployed",
            ["return address(this) != address(0);"],
            ["assert(address(this) != address(0));"],
        ))

    test_contract_name = cname + "_" + tool.capitalize() + "Test"
    tests_body = "\n".join(tests)

    sol = (
        "// AUTO-GENERATED by AuditTOOL — " + tool.upper() + " test wrapper\n"
        "// Wraps the original contract with property/invariant tests\n"
        "pragma solidity " + pragma + ";\n\n"
        + source + "\n\n"
        "contract " + test_contract_name + " is " + cname + " {\n"
        + tests_body
        + "}\n"
    )
    return sol


def _write_test_file(sol_code: str, work_dir: str, filename: str) -> str:
    """Записывает сгенерированный тест-контракт во временную папку."""
    path = os.path.join(work_dir, filename)
    with open(path, "w", encoding="utf-8") as f:
        f.write(sol_code)
    return path

def run_echidna(contract_path: str) -> list[dict]:
    """
    Echidna fuzzer — требует контракт с echidna_* тест-функциями.
    Скрипт автоматически:
      1. Определяет имя контракта из файла
      2. Создаёт минимальный echidna.yaml конфиг во временной папке
      3. Запускает echidna и парсит JSON-вывод
    """
    if not shutil.which("echidna"):
        _print("Echidna not found - skipping. (Install: https://github.com/crytic/echidna/releases)", "yellow")
        return []

    # Читаем исходник чтобы найти имя контракта и echidna_* функции
    try:
        with open(contract_path, "r", encoding="utf-8") as f:
            source = f.read()
    except OSError as e:
        _print(f"Echidna: cannot read contract: {e}", "yellow")
        return []

    # Парсим контракт
    info = _extract_contract_info(source)
    contract_name = info["contract_name"]

    # Проверяем — есть ли уже echidna_* тесты в контракте клиента
    echidna_tests = re.findall(r"function\s+(echidna_\w+)\s*\(", source)

    work_dir    = tempfile.mkdtemp(prefix="echidna_")
    config_path = os.path.join(work_dir, "echidna.yaml")

    if echidna_tests:
        # Клиент уже написал тесты — используем оригинальный файл
        _print(f"Echidna: using {len(echidna_tests)} existing test(s): {', '.join(echidna_tests)}", "cyan")
        target_path   = contract_path
        target_cname  = contract_name
    else:
        # Автогенерируем тест-контракт на основе анализа структуры контракта
        _print("Echidna: no echidna_* tests found — auto-generating test wrapper...", "cyan")
        test_sol      = _generate_test_contract(source, info, "echidna")
        target_path   = _write_test_file(test_sol, work_dir, "echidna_test.sol")
        target_cname  = f"{contract_name}_EchidnaTest" if contract_name else None
        _print(f"Echidna: generated test wrapper: {os.path.basename(target_path)}", "green")

    # Конфиг
    with open(config_path, "w") as f:
        f.write("testMode: property\ntestLimit: 50000\nshrinkLimit: 5000\ntimeout: 120\nformat: json\n")

    cmd = ["echidna", target_path, "--config", config_path, "--format", "json"]
    if target_cname:
        cmd += ["--contract", target_cname]

    code, stdout, stderr = run_tool(cmd, timeout=180)

    findings = []
    try:
        # Echidna выводит JSON-строки построчно
        for line in (stdout or "").splitlines():
            line = line.strip()
            if not line:
                continue
            try:
                data = json.loads(line)
            except json.JSONDecodeError:
                continue
            # Формат: {"event": "property_failed", "name": "echidna_x", "call_sequence": [...]}
            event = data.get("event", "")
            if event in ("property_failed", "assertion_failed"):
                name   = data.get("name", "unknown")
                calls  = data.get("call_sequence", [])
                call_s = " → ".join(str(c) for c in calls[:3]) if calls else "N/A"
                findings.append({
                    "type":           "echidna-property-violation",
                    "severity":       "High",
                    "description":    f"Echidna violated property: {name}. Call sequence: {call_s}",
                    "location":       f"Function: {name}",
                    "recommendation": (
                        "Inspect the counterexample call sequence above and fix the invariant. "
                        "Ensure all state transitions preserve this property."
                    ),
                    "tool":    "Echidna",
                    "swc_id":  "N/A",
                })
    except Exception as exc:
        logger.warning("Echidna output parse error: %s", exc)

    # Fallback: если stdout пустой но есть stderr — логируем
    if not findings and stderr:
        logger.info("Echidna stderr: %s", stderr[:500])
        if "No tests found" in stderr or "error" in stderr.lower():
            _print(f"Echidna warning: {stderr.strip()[:200]}", "yellow")

    try:
        shutil.rmtree(work_dir, ignore_errors=True)
    except Exception:
        pass

    _print(f"Echidna: {len(findings)} violation(s).", "green" if not findings else "red")
    return findings


def run_medusa(contract_path: str) -> list[dict]:
    """
    Medusa fuzzer (Trail of Bits) — работает через временный Foundry-совместимый проект.
    Автоматически создаёт medusa.json конфиг и структуру папок.
    """
    if not shutil.which("medusa"):
        _print("Medusa not found - skipping. (Install: https://github.com/crytic/medusa/releases)", "yellow")
        return []

    try:
        with open(contract_path, "r", encoding="utf-8") as f:
            source = f.read()
    except OSError as e:
        _print(f"Medusa: cannot read contract: {e}", "yellow")
        return []

    # Парсим контракт
    info = _extract_contract_info(source)
    contract_name = info["contract_name"] or "TestContract"

    # Проверяем — есть ли уже property_*/fuzz_* тесты
    property_tests = re.findall(r"function\s+(property_\w+|fuzz_\w+)\s*\(", source)

    work_dir = tempfile.mkdtemp(prefix="medusa_")
    src_dir  = os.path.join(work_dir, "src")
    os.makedirs(src_dir, exist_ok=True)

    import shutil as _shutil
    if property_tests:
        # Используем оригинальный файл
        _print(f"Medusa: using {len(property_tests)} existing test(s): {', '.join(property_tests)}", "cyan")
        dest_sol      = os.path.join(src_dir, os.path.basename(contract_path))
        _shutil.copy2(contract_path, dest_sol)
        target_cname  = contract_name
    else:
        # Автогенерируем
        _print("Medusa: no property_* tests found — auto-generating test wrapper...", "cyan")
        test_sol      = _generate_test_contract(source, info, "medusa")
        dest_sol      = _write_test_file(test_sol, src_dir, "medusa_test.sol")
        target_cname  = f"{contract_name}_MedusaTest"
        _print(f"Medusa: generated test wrapper: {os.path.basename(dest_sol)}", "green")

    # medusa.json конфиг
    medusa_cfg = {
        "fuzzing": {
            "workers": 1,
            "workerResetLimit": 50,
            "timeout": 120,
            "testLimit": 50000,
            "shrinkLimit": 5000,
            "targetContracts": [target_cname],
            "propertyTesting": {
                "enabled": True,
                "testPrefixes": ["property_", "fuzz_"],
            },
        },
        "compilation": {
            "platform": "crytic-compile",
            "platformConfig": {
                "target": src_dir,
            },
        },
        "logging": {"level": "error"},
    }
    cfg_path = os.path.join(work_dir, "medusa.json")
    with open(cfg_path, "w", encoding="utf-8") as f:
        json.dump(medusa_cfg, f, indent=2)

    code, stdout, stderr = run_tool(
        ["medusa", "fuzz", "--config", cfg_path],
        timeout=180,
    )

    findings = []
    combined = (stdout or "") + (stderr or "")
    # Medusa выводит текстовые строки о нарушениях
    failed_pattern = re.compile(r"FAILED\s+(\w+)|property violated[:\s]+(\w+)", re.IGNORECASE)
    for m in failed_pattern.finditer(combined):
        name = m.group(1) or m.group(2) or "unknown"
        findings.append({
            "type":           "medusa-property-violation",
            "severity":       "High",
            "description":    f"Medusa violated property: {name}",
            "location":       f"Function: {name}",
            "recommendation": (
                "Inspect the Medusa counterexample call sequence and fix the invariant. "
                "Ensure all state transitions preserve this property."
            ),
            "tool":    "Medusa",
            "swc_id":  "N/A",
        })

    try:
        shutil.rmtree(work_dir, ignore_errors=True)
    except Exception:
        pass

    _print(f"Medusa: {len(findings)} violation(s).", "green" if not findings else "red")
    return findings


def run_halmos(contract_path: str) -> list[dict]:
    """
    Halmos — символическая верификация (formal verification).
    Работает через временный Foundry-совместимый проект.
    Находит нарушения assert() и проверяет все возможные входные значения.
    """
    if not shutil.which("halmos"):
        _print("Halmos not found - skipping. (pip install halmos)", "yellow")
        return []

    try:
        with open(contract_path, "r", encoding="utf-8") as f:
            source = f.read()
    except OSError as e:
        _print(f"Halmos: cannot read contract: {e}", "yellow")
        return []

    # Парсим контракт
    info = _extract_contract_info(source)
    contract_name = info["contract_name"]

    # Проверяем — есть ли уже check_*/prove_* тесты
    check_tests = re.findall(r"function\s+(check_\w+|prove_\w+)\s*\(", source)

    work_dir = tempfile.mkdtemp(prefix="halmos_")
    src_dir  = os.path.join(work_dir, "src")
    test_dir = os.path.join(work_dir, "test")
    os.makedirs(src_dir,  exist_ok=True)
    os.makedirs(test_dir, exist_ok=True)

    import shutil as _shutil
    if check_tests:
        _print(f"Halmos: using {len(check_tests)} existing test(s): {', '.join(check_tests)}", "cyan")
        dest_sol      = os.path.join(test_dir, os.path.basename(contract_path))
        _shutil.copy2(contract_path, dest_sol)
        target_cname  = contract_name
    else:
        _print("Halmos: no check_* tests found — auto-generating symbolic test wrapper...", "cyan")
        test_sol      = _generate_test_contract(source, info, "halmos")
        dest_sol      = _write_test_file(test_sol, test_dir, "halmos_test.sol")
        target_cname  = f"{contract_name}_HalmosTest" if contract_name else None
        _print(f"Halmos: generated test wrapper: {os.path.basename(dest_sol)}", "green")

    # foundry.toml минимальный
    foundry_toml = os.path.join(work_dir, "foundry.toml")
    with open(foundry_toml, "w") as f:
        f.write("[profile.default]\nsrc = 'src'\ntest = 'test'\nout = 'out'\n")

    cmd = ["halmos", "--root", work_dir, "--json-output", "-"]
    if target_cname:
        cmd += ["--contract", target_cname]

    code, stdout, stderr = run_tool(cmd, timeout=900)

    findings = []
    try:
        data = json.loads(stdout) if stdout and stdout.strip().startswith("{") else {}
        results = data.get("results", data.get("halmos_results", []))
        for item in results:
            status = str(item.get("status", "")).lower()
            if "pass" in status or "safe" in status:
                continue  # пропускаем успешные проверки
            sev = (
                "High"   if ("fail" in status or "counterexample" in status or "violation" in status) else
                "Medium" if "timeout" in status else
                "Low"
            )
            name = item.get("name", item.get("test", "unknown"))
            findings.append({
                "type":           f"halmos:{name}",
                "severity":       sev,
                "description":    (
                    f"Halmos formal verification failed for: {name}. "
                    f"Status: {item.get('status', 'unknown')}. "
                    + (f"Counterexample: {item.get('counterexample', '')}" if item.get("counterexample") else "")
                ),
                "location":       item.get("location", f"Function: {name}"),
                "recommendation": (
                    "Review the counterexample provided by Halmos and fix the property violation. "
                    "Ensure the invariant holds for all possible symbolic inputs."
                ),
                "tool":    "Halmos",
                "swc_id":  "N/A",
            })
    except (json.JSONDecodeError, Exception) as exc:
        # Fallback: парсим текстовый вывод
        logger.info("Halmos JSON parse failed (%s), falling back to text parsing", exc)
        fail_pattern = re.compile(r"FAIL\s+(\w+)|counterexample found[:\s]+(\w+)", re.IGNORECASE)
        for m in fail_pattern.finditer((stdout or "") + (stderr or "")):
            name = m.group(1) or m.group(2) or "unknown"
            findings.append({
                "type":           f"halmos:{name}",
                "severity":       "High",
                "description":    f"Halmos found counterexample for: {name}",
                "location":       f"Function: {name}",
                "recommendation": "Fix the property violation — Halmos found an input that breaks it.",
                "tool":    "Halmos",
                "swc_id":  "N/A",
            })

    try:
        shutil.rmtree(work_dir, ignore_errors=True)
    except Exception:
        pass

    _print(f"Halmos: {len(findings)} violation(s).", "green" if not findings else "red")
    return findings


def run_static_analysis(contract_source: str, contract_path: str) -> list[dict]:
    """
    Regex-based static analysis.
    Improvements over previous version:
      • Strips comments before matching → fewer false positives
      • Regex findings are tagged Info/Low (Slither is the real static engine)
        Critical/High regex findings are kept only for patterns with very high
        signal-to-noise (mint without AC, proxy without EIP-1967).
    """
    _print("Running static analysis (regex + comment-strip)...", "cyan")

    clean_source = _strip_comments(contract_source)
    lines_clean  = clean_source.splitlines()
    lines_orig   = contract_source.splitlines()   # for display (original line text)
    findings     = []

    # ── Severity downgrade map for regex (reduce noise) ───────────────────────
    # Slither already covers High/Critical accurately — regex is a pre-check.
    # ── Все regex-находки → Info (Slither даст точный severity) ─────────────
    # Исключение: unlimited_mint и proxy_issues — отдельно ниже, без clamp.
    _REGEX_SEV_CLAMP = {
        "Critical": "Info",
        "High":     "Info",
        "Medium":   "Info",
        "Low":      "Info",
        "Info":     "Info",
    }

    for pat_key, title, description, recommendation, severity in LINE_CHECKS:
        pat = PATTERNS.get(pat_key)
        if not pat:
            continue
        clamped = _REGEX_SEV_CLAMP.get(severity, "Info")
        for lineno, line in enumerate(lines_clean, 1):
            if pat.search(line):
                findings.append({
                    "type":           pat_key,
                    "severity":       clamped,
                    "description":    f"[Regex] {description}",
                    "location":       f"Line {lineno}",
                    "recommendation": recommendation,
                    "tool":           "StaticAnalysis",
                    "swc_id":         SWC_IDS.get(pat_key, "N/A"),
                })

    for pat in DEPRECATED_PATTERNS:
        for lineno, line in enumerate(lines_clean, 1):
            if pat.search(line):
                findings.append({
                    "type":           "deprecated_function",
                    "severity":       "Info",
                    "description":    f"[Regex] Deprecated construct detected: {pat.pattern}",
                    "location":       f"Line {lineno}",
                    "recommendation": "Replace with modern Solidity equivalents.",
                    "tool":           "StaticAnalysis",
                    "swc_id":         SWC_IDS.get("deprecated_function", "N/A"),
                })

    # ── High-confidence contract-wide checks (keep severity, very low FP) ─────
    if PATTERNS["mint_function"].search(clean_source):
        has_ac = (
            PATTERNS["only_owner"].search(clean_source) or
            PATTERNS["role_based"].search(clean_source)
        )
        if not has_ac:
            findings.append({
                "type":           "unlimited_mint",
                "severity":       "Critical",
                "description":    "mint() function exists without any access control.",
                "location":       "Contract-wide",
                "recommendation": "Restrict mint with onlyOwner or role-based access control.",
                "tool":           "StaticAnalysis",
                "swc_id":         "Custom-001",
            })

    if PATTERNS["proxy_delegatecall"].search(clean_source):
        if not PATTERNS["implementation_storage"].search(clean_source):
            findings.append({
                "type":           "proxy_issues",
                "severity":       "High",
                "description":    "Proxy uses delegatecall without a secured EIP-1967 storage slot.",
                "location":       "Contract-wide",
                "recommendation": "Use EIP-1967 unstructured storage slot for the implementation address.",
                "tool":           "StaticAnalysis",
                "swc_id":         "Custom-002",
            })

    findings += _check_solidity_version(contract_source)

    _print(f"Static analysis: {len(findings)} finding(s).", "green")
    return findings


def _check_solidity_version(contract_source: str) -> list[dict]:
    findings = []
    lines = contract_source.splitlines()
    pragma_re = re.compile(r'^\s*pragma\s+solidity\s+([^;]+);', re.IGNORECASE)
    version_re = re.compile(r'(\d+)\.(\d+)\.(\d+)')
    floating_re = re.compile(r'[\^~]')

    pragma_lines = []
    for lineno, line in enumerate(lines, 1):
        m = pragma_re.search(line)
        if m:
            pragma_lines.append((lineno, m.group(1).strip()))

    if not pragma_lines:
        findings.append({
            "type": "missing_pragma",
            "severity": "High",
            "description": "No 'pragma solidity' directive found.",
            "location": "Contract-wide",
            "recommendation": "Add e.g. pragma solidity ^0.8.20;",
            "tool": "StaticAnalysis",
            "swc_id": "SWC-103",
        })
        return findings

    for lineno, ver_spec in pragma_lines:
        location = f"Line {lineno}"

        if floating_re.search(ver_spec):
            findings.append({
                "type": "floating_pragma",
                "severity": "Medium",
                "description": f"Floating pragma detected: '{ver_spec}'.",
                "location": location,
                "recommendation": "Lock to specific version, e.g. pragma solidity 0.8.20;",
                "tool": "StaticAnalysis",
                "swc_id": "SWC-103",
            })

        versions = version_re.findall(ver_spec)
        if not versions:
            continue

        major, minor, patch = map(int, versions[-1])
        ver_str = f"{major}.{minor}.{patch}"

        if major == 0 and minor < 8:
            findings.append({
                "type": "outdated_solidity_version",
                "severity": "High",
                "description": f"Solidity {ver_str} < 0.8.0 — no overflow protection.",
                "location": location,
                "recommendation": "Upgrade to >= 0.8.20 or use SafeMath.",
                "tool": "StaticAnalysis",
                "swc_id": "SWC-102",
            })
        elif major == 0 and minor == 8 and patch < 16:
            findings.append({
                "type": "vulnerable_solidity_version",
                "severity": "Medium",
                "description": f"Solidity {ver_str} (0.8.0–0.8.15) has known bugs.",
                "location": location,
                "recommendation": "Upgrade to >= 0.8.20.",
                "tool": "StaticAnalysis",
                "swc_id": "SWC-102",
            })
        elif major == 0 and minor == 8 and patch < 19:
            findings.append({
                "type": "slightly_outdated_solidity_version",
                "severity": "Low",
                "description": f"Solidity {ver_str} (0.8.16–0.8.18) has minor bugs.",
                "location": location,
                "recommendation": "Upgrade to >= 0.8.20.",
                "tool": "StaticAnalysis",
                "swc_id": "SWC-102",
            })

    return findings


def estimate_gas(contract_path: str, contract_source: str) -> dict:
    if not shutil.which("solc"):
        return {"estimated_gas": "N/A", "function_gas": {}}

    ver_match = PATTERNS["solidity_version"].search(contract_source)
    solidity_version = ver_match.group(1) if ver_match else None

    cmd = ["solc", "--gas", contract_path]
    if solidity_version:
        cmd.insert(1, f"--evm-version={solidity_version}")

    code, stdout, stderr = run_tool(cmd, timeout=300)
    if code != 0:
        return {"estimated_gas": "Error", "function_gas": {}}

    metrics = {"estimated_gas": "N/A", "function_gas": {}}
    m = re.search(r"External calls:.*?(\d+)", stdout, re.DOTALL)
    if m:
        metrics["estimated_gas"] = int(m.group(1))
    for fm in re.finditer(r"function\s+(\w+)\s*\(.*?\).*?Gas:\s*(\d+)", stdout, re.DOTALL):
        metrics["function_gas"][fm.group(1)] = int(fm.group(2))
    return metrics


# ─────────────────────────────────────────────────────────────────────────────
#  DEDUPLICATION & SORTING
# ─────────────────────────────────────────────────────────────────────────────

SEVERITY_ORDER = {"Critical": 0, "High": 1, "Medium": 2, "Low": 3, "Info": 4}


def deduplicate(findings: list[dict]) -> list[dict]:
    seen = set()
    result = []
    for f in findings:
        key = (f.get("type", ""), f.get("severity", ""))
        if key not in seen:
            seen.add(key)
            result.append(f)
    # Детерминированная сортировка: первично по severity,
    # вторично по (type, location) — чтобы порядок был стабильным даже при
    # одинаковом наборе находок из разных инструментов.
    result.sort(key=lambda x: (
        SEVERITY_ORDER.get(x.get("severity", "Low"), 4),
        x.get("type", ""),
        x.get("location", ""),
    ))
    return result


# ─────────────────────────────────────────────────────────────────────────────
#  CONSOLE REPORT
# ─────────────────────────────────────────────────────────────────────────────

SEV_COLOR = {
    "Critical": "bold red",
    "High":     "red",
    "Medium":   "yellow",
    "Low":      "cyan",
    "Info":     "dim white",
}

# Rich inline-style severity badges
_SEV_BADGE = {
    "Critical": "[bold white on red] CRITICAL [/bold white on red]",
    "High":     "[bold white on dark_orange] HIGH     [/bold white on dark_orange]",
    "Medium":   "[bold black on yellow] MEDIUM   [/bold black on yellow]",
    "Low":      "[bold white on blue] LOW      [/bold white on blue]",
    "Info":     "[bold black on bright_black] INFO     [/bold black on bright_black]",
}

# Panel border colours per severity
_SEV_BORDER = {
    "Critical": "red",
    "High":     "dark_orange",
    "Medium":   "yellow",
    "Low":      "blue",
    "Info":     "bright_black",
}

# Top-level risk banner
_RISK_LABEL = {
    "Critical": "[bold white on red]  ● CRITICAL RISK — DO NOT DEPLOY  [/bold white on red]",
    "High":     "[bold white on dark_orange]  ● HIGH RISK — FIX BEFORE DEPLOYMENT  [/bold white on dark_orange]",
    "Medium":   "[bold black on yellow]  ● MEDIUM RISK — REVIEW RECOMMENDED  [/bold black on yellow]",
    "Low":      "[bold white on blue]  ● LOW RISK — MONITOR  [/bold white on blue]",
    "Info":     "[bold bright_black]  ● INFORMATIONAL — NO IMMEDIATE ACTION REQUIRED  [/bold bright_black]",
}


def _overall_risk(counts: dict) -> str:
    for sev in ["Critical", "High", "Medium", "Low", "Info"]:
        if counts.get(sev, 0) > 0:
            return sev
    return "Info"


def print_console_report(findings: list[dict], contract_path: str, gas_metrics: dict) -> None:
    contract_name = os.path.basename(contract_path)

    if console:
        counts: dict = {}
        for f in findings:
            counts[f["severity"]] = counts.get(f["severity"], 0) + 1

        overall = _overall_risk(counts)
        now_str = datetime.now().strftime("%Y-%m-%d  %H:%M")
        total   = len(findings) or 1

        # ── Banner ───────────────────────────────────────────────────────
        console.print()
        console.rule("[bold cyan]SMART CONTRACT SECURITY AUDIT[/bold cyan]", style="cyan")
        console.print()

        console.print(Panel(
            f"  [dim]Contract :[/dim]  [bold white]{contract_name}[/bold white]\n"
            f"  [dim]Date     :[/dim]  [white]{now_str}[/white]\n"
            f"  [dim]Findings :[/dim]  [bold white]{len(findings)}[/bold white]  total",
            border_style="bright_black", padding=(0, 1),
        ))
        console.print()
        console.print("  " + _RISK_LABEL.get(overall, overall))
        console.print()

        # ── Severity distribution bar-chart ──────────────────────────────
        chart = Table(
            box=rich_box.SIMPLE_HEAD, show_header=True, header_style="bold white",
            title="[bold]Severity Distribution[/bold]", title_justify="left",
            min_width=56, padding=(0, 1),
        )
        chart.add_column("Severity",  width=10)
        chart.add_column("Count",     justify="center", width=7)
        chart.add_column("Bar",       width=22)
        chart.add_column("Share",     justify="right",  width=7)

        for sev in ["Critical", "High", "Medium", "Low", "Info"]:
            n = counts.get(sev, 0)
            if n == 0:
                continue
            bar_len = max(1, round(n / total * 18))
            bar     = "█" * bar_len + "░" * (18 - bar_len)
            pct     = f"{round(n / total * 100)}%"
            col     = SEV_COLOR[sev]
            chart.add_row(
                f"[{col}]{sev}[/{col}]",
                f"[bold {col}]{n}[/bold {col}]",
                f"[{col}]{bar}[/{col}]",
                f"[{col}]{pct}[/{col}]",
            )
        console.print(chart)
        console.print()

        # ── Findings overview table ───────────────────────────────────────
        if findings:
            ov = Table(
                box=rich_box.SIMPLE_HEAD, show_header=True, header_style="bold white",
                title="[bold]Findings Overview[/bold]", title_justify="left",
                padding=(0, 1),
            )
            ov.add_column("#",          width=4,  justify="right")
            ov.add_column("Priority",   width=8,  justify="center")
            ov.add_column("CVSS",       width=6,  justify="center")
            ov.add_column("Severity",   width=10)
            ov.add_column("Type",       width=28)
            ov.add_column("Location",   width=14)
            ov.add_column("Tool",       width=14)

            for idx, f in enumerate(findings, 1):
                sev   = f.get("severity", "Low")
                col   = SEV_COLOR.get(sev, "white")
                score = f.get("cvss_score", "—")
                prio  = f.get("risk_priority", "—")
                score_str = f"{score:.1f}" if isinstance(score, float) else str(score)
                ov.add_row(
                    str(idx),
                    f"[bold]#{prio}[/bold]",
                    f"[{col}]{score_str}[/{col}]",
                    f"[{col}]{sev}[/{col}]",
                    f.get("type", "")[:28],
                    str(f.get("location", ""))[:14],
                    f.get("tool", ""),
                )
            console.print(ov)
            console.print()

        # ── Detailed findings + fix guides ────────────────────────────────
        if findings:
            console.rule("[bold]Detailed Findings & Fix Guides[/bold]", style="bright_black")
            console.print()

            for idx, f in enumerate(findings, 1):
                sev   = f.get("severity", "Low")
                badge = _SEV_BADGE.get(sev, sev)
                ftype = f.get("type", "unknown")
                desc  = f.get("description", "")
                rec   = f.get("recommendation", "")
                tool  = f.get("tool", "—")
                loc   = str(f.get("location", "—"))
                swc   = f.get("swc_id", "—")
                cvss  = f.get("cvss_score", "N/A")
                cvss_str = f"{cvss:.1f}" if isinstance(cvss, float) else str(cvss)
                cvss_vec = f.get("cvss_vector", "N/A")
                prio  = f.get("risk_priority", "—")

                # Finding card
                console.print(Panel(
                    f"  [dim]#{idx:02d}[/dim]  {badge}  [dim]Risk Priority: #{prio}[/dim]\n\n"
                    f"  [bold]Type        :[/bold]  {ftype}\n"
                    f"  [bold]SWC         :[/bold]  {swc}\n"
                    f"  [bold]CVSS Score  :[/bold]  [bold yellow]{cvss_str}[/bold yellow]  "
                    f"[dim]({cvss_vec})[/dim]\n"
                    f"  [bold]Tool        :[/bold]  {tool}\n"
                    f"  [bold]Location    :[/bold]  {loc}\n\n"
                    f"  [bold]Description :[/bold]\n"
                    f"  {desc}\n\n"
                    f"  [bold]Recommendation :[/bold]\n"
                    f"  [green]{rec}[/green]",
                    border_style=_SEV_BORDER.get(sev, "white"),
                    padding=(0, 1),
                ))

                # Fix guide panel
                guide = BUG_FIX_GUIDES.get(ftype, {})
                expl      = guide.get("explanation", "")
                bad_code  = guide.get("bad", "")
                good_code = guide.get("good", "")

                if expl or bad_code or good_code:
                    parts = []
                    if expl:
                        parts.append(f"[bold yellow]How to Fix:[/bold yellow]\n{expl}")
                    if bad_code:
                        parts.append(
                            "[bold red]❌  Vulnerable code:[/bold red]\n"
                            + "\n".join(f"[red]{line}[/red]" for line in bad_code.splitlines())
                        )
                    if good_code:
                        parts.append(
                            "[bold green]✅  Fixed code:[/bold green]\n"
                            + "\n".join(f"[green]{line}[/green]" for line in good_code.splitlines())
                        )
                    console.print(Panel(
                        "\n\n".join(parts),
                        title="[bold]Fix Guide[/bold]",
                        border_style="bright_black",
                        padding=(0, 2),
                    ))

                console.print()

        else:
            console.print(Panel(
                "[bold green]  ✔  No vulnerabilities detected.[/bold green]",
                border_style="green", padding=(0, 2),
            ))
            console.print()

        # ── Gas estimation ────────────────────────────────────────────────
        gas_val = gas_metrics.get("estimated_gas", "N/A")
        fn_gas  = gas_metrics.get("function_gas", {})
        if gas_val not in ("N/A", "Error") or fn_gas:
            console.rule("[bold]Gas Estimation[/bold]", style="bright_black")
            console.print()
            if gas_val not in ("N/A", "Error"):
                gv = f"{gas_val:,}" if isinstance(gas_val, int) else str(gas_val)
                console.print(f"  [bold]Estimated external-call gas:[/bold]  {gv}")
            if fn_gas:
                g_tbl = Table(
                    box=rich_box.SIMPLE_HEAD, header_style="bold white",
                    title="[bold]Function Gas[/bold]", title_justify="left",
                )
                g_tbl.add_column("Function", style="white")
                g_tbl.add_column("Gas", justify="right", style="cyan")
                for fn, gas in sorted(fn_gas.items(), key=lambda x: -x[1]):
                    g_tbl.add_row(fn, f"{gas:,}" if isinstance(gas, int) else str(gas))
                console.print(g_tbl)
            console.print()

        console.rule(style="cyan")
        console.print()

    else:
        # ── Plain-text fallback (no rich) ─────────────────────────────────
        sep = "=" * 72
        print(f"\n{sep}")
        print("  SMART CONTRACT SECURITY AUDIT REPORT")
        print(f"  Contract : {contract_name}")
        print(f"  Date     : {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        print(f"  Findings : {len(findings)}")
        print(sep)
        counts2: dict = {}
        for f in findings:
            counts2[f["severity"]] = counts2.get(f["severity"], 0) + 1
        total2 = len(findings) or 1
        print("\nSEVERITY DISTRIBUTION")
        print("-" * 40)
        for sev in ["Critical", "High", "Medium", "Low", "Info"]:
            n = counts2.get(sev, 0)
            if n:
                bar = "█" * max(1, round(n / total2 * 20))
                print(f"  {sev:<10}  {n:>3}  {bar}  {round(n/total2*100)}%")
        print()
        for idx, f in enumerate(findings, 1):
            print(f"\n{'─'*72}")
            print(f"  [{idx:02d}] {f.get('severity','').upper()} — {f.get('type','')}")
            print(f"       SWC      : {f.get('swc_id','—')}")
            print(f"       Tool     : {f.get('tool','—')}")
            print(f"       Location : {f.get('location','—')}")
            print(f"       Desc     : {f.get('description','')}")
            print(f"       Fix      : {f.get('recommendation','')}")
            guide = BUG_FIX_GUIDES.get(f.get("type", ""), {})
            if guide.get("explanation"):
                print(f"\n  HOW TO FIX:\n  {guide['explanation']}")
            if guide.get("bad"):
                print(f"\n  VULNERABLE CODE:\n{guide['bad']}")
            if guide.get("good"):
                print(f"\n  FIXED CODE:\n{guide['good']}")
        gas_val2 = gas_metrics.get("estimated_gas", "N/A")
        if gas_val2 not in ("N/A", "Error"):
            print(f"\nGas estimate: {gas_val2}")
        print(f"\n{sep}\n")


# ─────────────────────────────────────────────────────────────────────────────
#  DOCX REPORT
# ─────────────────────────────────────────────────────────────────────────────

_SEV_RGB = {}
if HAS_DOCX:
    _SEV_RGB = {
        "Critical": RGBColor(192, 0,   0  ),
        "High":     RGBColor(230, 100, 0  ),
        "Medium":   RGBColor(190, 140, 0  ),
        "Low":      RGBColor(0,   100, 170),
        "Info":     RGBColor(100, 100, 100),
    }

_SEV_BG_HEX = {
    "Critical": "F8D7DA",
    "High":     "FDEBD0",
    "Medium":   "FFF9C4",
    "Low":      "D4EDDA",
    "Info":     "F0F0F0",
}


def _set_cell_bg(cell, hex_color: str) -> None:
    tc   = cell._tc
    tcPr = tc.get_or_add_tcPr()
    shd  = OxmlElement("w:shd")
    shd.set(qn("w:val"),   "clear")
    shd.set(qn("w:color"), "auto")
    shd.set(qn("w:fill"),  hex_color)
    tcPr.append(shd)


def _cell_margins(cell, top=70, bottom=70, left=110, right=110) -> None:
    tc    = cell._tc
    tcPr  = tc.get_or_add_tcPr()
    tcMar = OxmlElement("w:tcMar")
    for side, val in (("top", top), ("bottom", bottom), ("left", left), ("right", right)):
        el = OxmlElement(f"w:{side}")
        el.set(qn("w:w"),    str(val))
        el.set(qn("w:type"), "dxa")
        tcMar.append(el)
    tcPr.append(tcMar)


def _hdr_cell(cell, text: str) -> None:
    """Dark navy header cell, white bold text, centred."""
    _set_cell_bg(cell, "0D2137")
    _cell_margins(cell, 100, 100, 140, 140)
    p   = cell.paragraphs[0]
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = p.runs[0] if p.runs else p.add_run()
    run.text = text
    run.bold = True
    run.font.name      = "Calibri"
    run.font.size      = Pt(9.5)
    run.font.color.rgb = RGBColor(0xFF, 0xFF, 0xFF)


def _data_cell(cell, text: str, bold: bool = False, size: float = 9.5,
               color: RGBColor = None, bg: str = None,
               align=WD_ALIGN_PARAGRAPH.LEFT) -> None:
    if bg:
        _set_cell_bg(cell, bg)
    _cell_margins(cell)
    p   = cell.paragraphs[0]
    p.alignment = align
    run = p.runs[0] if p.runs else p.add_run()
    run.text      = str(text)
    run.bold      = bold
    run.font.name = "Calibri"
    run.font.size = Pt(size)
    if color:
        run.font.color.rgb = color


def generate_docx_report(
    findings:        list[dict],
    contract_path:   str,
    gas_metrics:     dict,
    output_filename: str = DOC_OUTPUT,
) -> None:
    """
    Generate a professional audit report in .docx format.
    Fully self-contained — only python-docx required.
    If generate_report.js is present beside the script, the Node.js
    renderer is used instead for an even richer design.
    """
    _js_report = os.path.join(
        os.path.dirname(os.path.abspath(__file__)), "generate_report.js"
    )
    if shutil.which("node") and os.path.exists(_js_report):
        _generate_docx_nodejs(findings, contract_path, gas_metrics, output_filename, _js_report)
        return

    if not HAS_DOCX:
        _print("python-docx is not installed. Run: pip install python-docx", "red")
        return
    _generate_docx_python(findings, contract_path, gas_metrics, output_filename)


def _generate_docx_nodejs(
    findings: list[dict],
    contract_path: str,
    gas_metrics: dict,
    output_filename: str,
    js_script: str,
) -> None:
    contract_name = os.path.basename(contract_path)
    tools_used    = ", ".join(sorted({f.get("tool", "N/A") for f in findings})) or "N/A"
    now           = datetime.now().strftime("%B %d, %Y  %H:%M")
    report_data   = {
        "contract_name": contract_name,
        "audit_date":    now,
        "tools_used":    tools_used,
        "findings":      findings,
        "gas_metrics":   gas_metrics,
    }
    tmp_json = os.path.join(TEMP_DIR, f"audit_data_{os.getpid()}.json")
    try:
        with open(tmp_json, "w", encoding="utf-8") as fp:
            json.dump(report_data, fp, ensure_ascii=False)
        code, _, stderr = run_tool(
            ["node", js_script, tmp_json, output_filename], timeout=60
        )
        if code == 0 and os.path.exists(output_filename):
            _print(f"Word report saved: {output_filename}", "green")
            logger.info("DOCX report saved (Node.js): %s", os.path.abspath(output_filename))
            return
        _print(f"Node.js renderer failed ({stderr.strip()[:80]}), falling back to python-docx.", "yellow")
    except Exception as e:
        _print(f"Node.js renderer error: {e}. Falling back to python-docx.", "yellow")
    finally:
        if os.path.exists(tmp_json):
            os.remove(tmp_json)
    if HAS_DOCX:
        _generate_docx_python(findings, contract_path, gas_metrics, output_filename)
    else:
        _print("python-docx not installed either. Run: pip install python-docx", "red")


def _generate_docx_python(
    findings:        list[dict],
    contract_path:   str,
    gas_metrics:     dict,
    output_filename: str = DOC_OUTPUT,
) -> None:
    """Full professional report: cover page, charts, findings table, fix guides."""
    contract_name = os.path.basename(contract_path)
    now_str       = datetime.now().strftime("%B %d, %Y  %H:%M")
    tools_used    = ", ".join(sorted({f.get("tool", "N/A") for f in findings})) or "N/A"

    counts: dict = {"Critical": 0, "High": 0, "Medium": 0, "Low": 0}
    for f in findings:
        counts[f.get("severity", "Low")] = counts.get(f.get("severity", "Low"), 0) + 1

    overall_risk = next(
        (s for s in ["Critical", "High", "Medium", "Low", "Info"] if counts.get(s, 0) > 0), "Info"
    )
    total_f = len(findings) or 1

    # ── Document setup ────────────────────────────────────────────────────
    doc = DocxDocument()
    for section in doc.sections:
        section.top_margin    = Cm(2.2)
        section.bottom_margin = Cm(2.2)
        section.left_margin   = Cm(2.5)
        section.right_margin  = Cm(2.5)

    doc.styles["Normal"].font.name      = "Calibri"
    doc.styles["Normal"].font.size      = Pt(10.5)
    doc.styles["Normal"].font.color.rgb = RGBColor(0x2D, 0x37, 0x48)

    for h_name, h_pt in [("Heading 1", 14), ("Heading 2", 12), ("Heading 3", 10.5)]:
        s = doc.styles[h_name]
        s.font.name      = "Calibri"
        s.font.size      = Pt(h_pt)
        s.font.bold      = True
        s.font.color.rgb = RGBColor(0x0D, 0x21, 0x37)
        s.paragraph_format.space_before = Pt(16)
        s.paragraph_format.space_after  = Pt(5)

    # ── Local helpers ─────────────────────────────────────────────────────
    def _accent_rule():
        p    = doc.add_paragraph()
        pPr  = p._p.get_or_add_pPr()
        pBdr = OxmlElement("w:pBdr")
        bot  = OxmlElement("w:bottom")
        bot.set(qn("w:val"),   "single")
        bot.set(qn("w:sz"),    "6")
        bot.set(qn("w:space"), "1")
        bot.set(qn("w:color"), "00A8E8")
        pBdr.append(bot)
        pPr.append(pBdr)
        p.paragraph_format.space_before = Pt(0)
        p.paragraph_format.space_after  = Pt(6)

    def _code_block(doc_ref, label: str, code_text: str,
                    label_rgb: RGBColor, bg_hex: str) -> None:
        """Insert a labelled monospace code block."""
        lp = doc_ref.add_paragraph()
        lp.paragraph_format.space_before = Pt(4)
        lp.paragraph_format.space_after  = Pt(2)
        lr = lp.add_run(label)
        lr.bold           = True
        lr.font.name      = "Calibri"
        lr.font.size      = Pt(9.5)
        lr.font.color.rgb = label_rgb

        tbl  = doc_ref.add_table(rows=1, cols=1)
        tbl.style = "Table Grid"
        cell = tbl.rows[0].cells[0]
        _set_cell_bg(cell, bg_hex)
        _cell_margins(cell, 100, 100, 160, 160)
        for para in list(cell.paragraphs):
            para._element.getparent().remove(para._element)
        for line in code_text.split("\n"):
            cp = cell.add_paragraph()
            cp.paragraph_format.space_before = Pt(0)
            cp.paragraph_format.space_after  = Pt(0)
            cr = cp.add_run(line if line else " ")
            cr.font.name      = "Courier New"
            cr.font.size      = Pt(8)
            cr.font.color.rgb = RGBColor(0xCC, 0xFF, 0xCC)

        sp = doc_ref.add_paragraph()
        sp.paragraph_format.space_after = Pt(4)

    # ═══════════════════════════════════════════════════════════════════════
    #  COVER PAGE  (dark navy background)
    # ═══════════════════════════════════════════════════════════════════════
    cov_tbl  = doc.add_table(rows=1, cols=1)
    cov_tbl.style = "Table Grid"
    cov_tbl.alignment = WD_TABLE_ALIGNMENT.CENTER

    # Force table to occupy 100% of the text-area width and sit centred
    cov_tbl_el  = cov_tbl._tbl
    cov_tblPr   = cov_tbl_el.find(qn("w:tblPr"))
    if cov_tblPr is None:
        cov_tblPr = OxmlElement("w:tblPr")
        cov_tbl_el.insert(0, cov_tblPr)

    # Remove any existing tblW / tblInd so we can set them cleanly
    for tag in ("w:tblW", "w:tblInd", "w:jc"):
        el = cov_tblPr.find(qn(tag))
        if el is not None:
            cov_tblPr.remove(el)

    cov_tblW = OxmlElement("w:tblW")
    cov_tblW.set(qn("w:w"),    "5000")   # 5000 = 100% in fiftieths-of-percent
    cov_tblW.set(qn("w:type"), "pct")
    cov_tblPr.append(cov_tblW)

    cov_jc = OxmlElement("w:jc")
    cov_jc.set(qn("w:val"), "center")
    cov_tblPr.append(cov_jc)

    cov_tblInd = OxmlElement("w:tblInd")
    cov_tblInd.set(qn("w:w"),    "0")
    cov_tblInd.set(qn("w:type"), "dxa")
    cov_tblPr.append(cov_tblInd)

    cov_cell = cov_tbl.rows[0].cells[0]
    _set_cell_bg(cov_cell, "0D2137")
    _cell_margins(cov_cell, 480, 480, 480, 480)
    cov_tc  = cov_cell._tc
    cov_tcPr = cov_tc.get_or_add_tcPr()
    for side in ("top", "left", "right", "bottom"):
        b = OxmlElement(f"w:{side}")
        b.set(qn("w:val"), "none")
        cov_tcPr.append(b)
    for para in list(cov_cell.paragraphs):
        para._element.getparent().remove(para._element)

    def _cov(text, size, hex_col, bold=False, safter=120):
        p = cov_cell.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p.paragraph_format.space_before = Pt(0)
        p.paragraph_format.space_after  = Pt(safter / 20)
        r = p.add_run(text)
        r.bold           = bold
        r.font.name      = "Calibri"
        r.font.size      = Pt(size)
        r.font.color.rgb = RGBColor(
            int(hex_col[0:2], 16), int(hex_col[2:4], 16), int(hex_col[4:6], 16)
        )

    _cov("SMART CONTRACT", 26, "FFFFFF", bold=True, safter=30)
    _cov("SECURITY AUDIT REPORT", 26, "00A8E8", bold=True, safter=120)
    _cov("─" * 44, 10, "00A8E8", safter=100)
    _cov(f"Contract:  {contract_name}", 11, "CCDDEE", safter=40)
    _cov(f"Date:      {now_str}",        11, "CCDDEE", safter=40)
    _cov(f"Tools:     {tools_used}",      9, "99AABB", safter=120)
    _risk_hex = {"Critical": "FF4444", "High": "FF8C00",
                 "Medium": "FFD700", "Low": "00C853", "Info": "999999"}
    _cov(f"OVERALL RISK:  {overall_risk.upper()}",
         15, _risk_hex.get(overall_risk, "FFFFFF"), bold=True, safter=30)
    _cov(f"{len(findings)} finding(s) detected", 10, "99AABB", safter=20)
    # CVSS summary on cover
    scores_list = [f.get("cvss_score") for f in findings if isinstance(f.get("cvss_score"), float)]
    if scores_list:
        max_c = max(scores_list)
        avg_c = sum(scores_list) / len(scores_list)
        _cov(f"Max CVSS: {max_c:.1f}  |  Avg CVSS: {avg_c:.1f}", 11, "99AABB", safter=60)
    doc.add_paragraph()

    # ═══════════════════════════════════════════════════════════════════════
    #  SECTION 1 — CONTRACT OVERVIEW
    # ═══════════════════════════════════════════════════════════════════════
    doc.add_heading("1.  Contract Overview", level=1)
    _accent_rule()

    scores_ov = [f.get("cvss_score") for f in findings if isinstance(f.get("cvss_score"), float)]
    max_cvss_ov = f"{max(scores_ov):.1f}" if scores_ov else "N/A"
    avg_cvss_ov = f"{sum(scores_ov)/len(scores_ov):.1f}" if scores_ov else "N/A"

    ov_rows = [
        ("Contract File",   contract_name),
        ("Audit Date",      now_str),
        ("Total Findings",  str(len(findings))),
        ("Tools Used",      tools_used),
        ("Overall Risk",    overall_risk),
        ("Max CVSS Score",  max_cvss_ov),
        ("Avg CVSS Score",  avg_cvss_ov),
    ]
    ov_tbl = doc.add_table(rows=len(ov_rows), cols=2)
    ov_tbl.style = "Table Grid"
    for i, (lbl, val) in enumerate(ov_rows):
        row = ov_tbl.rows[i]
        _data_cell(row.cells[0], lbl, bold=True,
                   color=RGBColor(0x1A, 0x3A, 0x5C), bg="EAF0F8")
        _data_cell(row.cells[1], val,
                   bg="FFFFFF" if i % 2 == 0 else "F4F7FB")
    doc.add_paragraph()

    # ═══════════════════════════════════════════════════════════════════════
    #  SECTION 2 — EXECUTIVE SUMMARY  +  SEVERITY CHART
    # ═══════════════════════════════════════════════════════════════════════
    doc.add_heading("2.  Executive Summary", level=1)
    _accent_rule()

    sev_status = {
        "Critical": "Must be fixed immediately. Do not deploy.",
        "High":     "Must be fixed before production deployment.",
        "Medium":   "Strongly recommended to fix before deployment.",
        "Low":      "Recommended; low immediate risk.",
        "Info":     "Informational only — regex pre-check, verify with Slither.",
    }

    if not findings:
        p = doc.add_paragraph(
            "No vulnerabilities detected. The contract passed all automated checks."
        )
        p.runs[0].font.color.rgb = RGBColor(0x15, 0x57, 0x24)
    else:
        # Summary table
        s_tbl = doc.add_table(rows=1, cols=3)
        s_tbl.style = "Table Grid"
        for i, h in enumerate(["Severity", "Count", "Status"]):
            _hdr_cell(s_tbl.rows[0].cells[i], h)
        for sev in ["Critical", "High", "Medium", "Low", "Info"]:
            n = counts.get(sev, 0)
            if n == 0:
                continue
            row   = s_tbl.add_row()
            bg    = _SEV_BG_HEX.get(sev, "EEEEEE")
            color = _SEV_RGB.get(sev)
            _data_cell(row.cells[0], sev,    bold=True, color=color, bg=bg,
                       align=WD_ALIGN_PARAGRAPH.CENTER)
            _data_cell(row.cells[1], str(n), bold=True, color=color, bg=bg,
                       align=WD_ALIGN_PARAGRAPH.CENTER)
            _data_cell(row.cells[2], sev_status[sev], bg=bg)
        doc.add_paragraph()

        # ── Severity Distribution Chart ───────────────────────────────────
        doc.add_heading("2.1  Severity Distribution Chart", level=2)
        _accent_rule()

        c_tbl = doc.add_table(rows=1, cols=4)
        c_tbl.style = "Table Grid"
        for h in ["Severity", "Count", "Proportion  (out of 20)", "Share"]:
            _hdr_cell(c_tbl.rows[0].cells[
                ["Severity", "Count", "Proportion  (out of 20)", "Share"].index(h)
            ], h)
        for sev in ["Critical", "High", "Medium", "Low", "Info"]:
            n = counts.get(sev, 0)
            if n == 0:
                continue
            row      = c_tbl.add_row()
            bg       = _SEV_BG_HEX.get(sev, "EEEEEE")
            color    = _SEV_RGB.get(sev)
            bar_fill = max(1, round(n / total_f * 20))
            pct      = f"{round(n / total_f * 100)}%"

            _data_cell(row.cells[0], sev,    bold=True, color=color, bg=bg,
                       align=WD_ALIGN_PARAGRAPH.CENTER)
            _data_cell(row.cells[1], str(n), bold=True, color=color, bg=bg,
                       align=WD_ALIGN_PARAGRAPH.CENTER)

            # Bar cell — filled ■ + empty □
            bar_cell = row.cells[2]
            _set_cell_bg(bar_cell, bg)
            _cell_margins(bar_cell)
            bp  = bar_cell.paragraphs[0]
            br1 = bp.add_run("■" * bar_fill)
            br1.font.name      = "Courier New"
            br1.font.size      = Pt(9)
            br1.font.color.rgb = color or RGBColor(0, 0, 0)
            br2 = bp.add_run("□" * (20 - bar_fill))
            br2.font.name      = "Courier New"
            br2.font.size      = Pt(9)
            br2.font.color.rgb = RGBColor(0xCC, 0xCC, 0xCC)

            _data_cell(row.cells[3], pct, bg=bg, align=WD_ALIGN_PARAGRAPH.CENTER)

    doc.add_paragraph()

    # ═══════════════════════════════════════════════════════════════════════
    #  SECTION 3 — DETAILED FINDINGS TABLE
    # ═══════════════════════════════════════════════════════════════════════
    doc.add_heading("3.  Detailed Findings", level=1)
    _accent_rule()

    if not findings:
        p = doc.add_paragraph("✔  No vulnerabilities found.")
        p.runs[0].font.color.rgb = RGBColor(0x15, 0x57, 0x24)
    else:
        # ─────────────────────────────────────────────────────────────────────
        #  Helper: build one compact finding mini-table + description block
        # ─────────────────────────────────────────────────────────────────────
        def _finding_block(doc_ref, idx: int, f: dict) -> None:
            """
            Renders a single finding as:
              [compact 7-col table: # | Severity | CVSS | SWC | Type | Tool | Location]
              [indented text block: Description … / Recommendation …]
              [thin separator line]
            """
            sev       = f.get("severity", "Low")
            sev_bg    = _SEV_BG_HEX.get(sev, "FFFFFF")
            color     = _SEV_RGB.get(sev)
            score     = f.get("cvss_score", "N/A")
            score_str = f"{score:.1f}" if isinstance(score, float) else str(score)

            # ── 7-column header + data in ONE table (2 rows) ─────────────────
            #   Cols: #  | Severity | CVSS | SWC  | Type | Tool | Location
            #   Widths (cm, total = 21.6):
            headers_f = ["#",  "Severity", "CVSS", "SWC",  "Type",       "Tool",  "Location"]
            col_cm_f  = [0.7,  2.2,        1.4,    1.6,    5.0,           2.2,     4.5]
            vals_f    = [
                str(idx),
                sev,
                score_str,
                f.get("swc_id",   "—"),
                f.get("type",     "—"),
                f.get("tool",     "—"),
                str(f.get("location", "—")),
            ]

            ftbl = doc_ref.add_table(rows=2, cols=len(headers_f))
            ftbl.style     = "Table Grid"
            ftbl.alignment = WD_TABLE_ALIGNMENT.LEFT

            # Lock widths
            tbl_el  = ftbl._tbl
            tblGrid = OxmlElement("w:tblGrid")
            for w in col_cm_f:
                gc = OxmlElement("w:gridCol")
                gc.set(qn("w:w"), str(int(w * 567)))
                tblGrid.append(gc)
            first_tr = tbl_el.find(qn("w:tr"))
            tbl_el.insert(list(tbl_el).index(first_tr), tblGrid)

            tblPr = tbl_el.find(qn("w:tblPr"))
            if tblPr is None:
                tblPr = OxmlElement("w:tblPr")
                tbl_el.insert(0, tblPr)
            tblLayout = OxmlElement("w:tblLayout")
            tblLayout.set(qn("w:type"), "fixed")
            tblPr.append(tblLayout)

            # Header row (row 0)
            hdr_row = ftbl.rows[0]
            for i, (h, w) in enumerate(zip(headers_f, col_cm_f)):
                cell = hdr_row.cells[i]
                cell.width = Cm(w)
                _set_cell_bg(cell, "0D2137")
                _cell_margins(cell, 55, 55, 80, 80)
                ph = cell.paragraphs[0]
                ph.alignment = WD_ALIGN_PARAGRAPH.CENTER
                run = ph.runs[0] if ph.runs else ph.add_run()
                run.text           = h
                run.bold           = True
                run.font.name      = "Calibri"
                run.font.size      = Pt(8.5)
                run.font.color.rgb = RGBColor(0xFF, 0xFF, 0xFF)

            # Data row (row 1)
            dat_row = ftbl.rows[1]
            for i, (val, w) in enumerate(zip(vals_f, col_cm_f)):
                cell = dat_row.cells[i]
                cell.width = Cm(w)
                is_sev   = i == 1
                is_score = i == 2
                bg       = sev_bg if is_sev else ("FFFFFF" if idx % 2 == 0 else "F4F7FB")
                _set_cell_bg(cell, bg)
                _cell_margins(cell, 55, 55, 80, 80)
                pc = cell.paragraphs[0]
                pc.alignment = WD_ALIGN_PARAGRAPH.CENTER if i <= 3 else WD_ALIGN_PARAGRAPH.LEFT
                run = pc.runs[0] if pc.runs else pc.add_run()
                run.text      = str(val)
                run.bold      = is_sev or (i == 0)
                run.font.name = "Calibri"
                run.font.size = Pt(9)
                if is_sev and color:
                    run.font.color.rgb = color
                elif is_score and color:
                    run.font.color.rgb = color

            # ── Description block (below the table, indented) ─────────────────
            desc = f.get("description", "").strip()
            rec  = f.get("recommendation", "").strip()
            vec  = f.get("cvss_vector", "")

            # Small spacer
            sp = doc_ref.add_paragraph()
            sp.paragraph_format.space_before = Pt(0)
            sp.paragraph_format.space_after  = Pt(0)

            def _label_text(label: str, text: str, label_color: RGBColor) -> None:
                p = doc_ref.add_paragraph()
                p.paragraph_format.space_before  = Pt(2)
                p.paragraph_format.space_after   = Pt(2)
                p.paragraph_format.left_indent   = Cm(0.4)
                rl = p.add_run(label + "  ")
                rl.bold           = True
                rl.font.name      = "Calibri"
                rl.font.size      = Pt(9)
                rl.font.color.rgb = label_color
                rt = p.add_run(text)
                rt.font.name      = "Calibri"
                rt.font.size      = Pt(9)
                rt.font.color.rgb = RGBColor(0x2D, 0x37, 0x48)

            if desc:
                _label_text("📋 Description:", desc, RGBColor(0x1A, 0x3A, 0x5C))
            if rec:
                _label_text("✅ Recommendation:", rec, RGBColor(0x21, 0x7A, 0x3C))
            if vec and vec != "N/A":
                _label_text("🔢 CVSS Vector:", vec, RGBColor(0x71, 0x80, 0x96))

            # Thin separator line
            sep = doc_ref.add_paragraph()
            sep.paragraph_format.space_before = Pt(4)
            sep.paragraph_format.space_after  = Pt(6)
            pPr_sep  = sep._p.get_or_add_pPr()
            pBdr_sep = OxmlElement("w:pBdr")
            bot_sep  = OxmlElement("w:bottom")
            bot_sep.set(qn("w:val"),   "single")
            bot_sep.set(qn("w:sz"),    "2")
            bot_sep.set(qn("w:space"), "1")
            bot_sep.set(qn("w:color"), "D0D7E3")
            pBdr_sep.append(bot_sep)
            pPr_sep.append(pBdr_sep)

        # ── Render every finding ──────────────────────────────────────────────
        for idx, f in enumerate(findings, 1):
            _finding_block(doc, idx, f)

    doc.add_paragraph()

    # ═══════════════════════════════════════════════════════════════════════
    #  SECTION 4 — FIX GUIDES  (one per unique bug type)
    # ═══════════════════════════════════════════════════════════════════════
    if findings:
        doc.add_heading("4.  Fix Guides", level=1)
        _accent_rule()

        intro = doc.add_paragraph(
            "For each unique vulnerability type detected, this section provides a brief "
            "explanation of the root cause, a code example showing the vulnerable pattern, "
            "and the corrected implementation."
        )
        intro.runs[0].font.size      = Pt(10)
        intro.runs[0].font.color.rgb = RGBColor(0x71, 0x80, 0x96)
        doc.add_paragraph()

        shown: set = set()
        guide_n    = 0
        for f in findings:
            ftype = f.get("type", "")
            if ftype in shown:
                continue
            shown.add(ftype)
            guide = BUG_FIX_GUIDES.get(ftype, {})
            if not guide:
                continue
            guide_n += 1

            sev       = f.get("severity", "Low")
            color     = _SEV_RGB.get(sev, RGBColor(0, 0, 0))
            bg        = _SEV_BG_HEX.get(sev, "F4F7FB")
            title_str = guide.get("title", ftype)
            expl      = guide.get("explanation", "")
            bad_code  = guide.get("bad",  "")
            good_code = guide.get("good", "")

            # Sub-heading
            sh = doc.add_heading(f"4.{guide_n}  {title_str}", level=2)
            sh.runs[0].font.color.rgb = color

            # Severity / SWC / Location / CVSS badge row  (4 cells)
            badge_tbl = doc.add_table(rows=1, cols=4)
            badge_tbl.style = "Table Grid"
            score_g     = f.get("cvss_score", "N/A")
            score_g_str = f"{score_g:.1f}" if isinstance(score_g, float) else str(score_g)
            _data_cell(badge_tbl.rows[0].cells[0], f"Severity: {sev}",
                       bold=True, color=color, bg=bg,
                       align=WD_ALIGN_PARAGRAPH.CENTER)
            _data_cell(badge_tbl.rows[0].cells[1],
                       f"CVSS: {score_g_str}",
                       bold=True, color=color, bg=bg,
                       align=WD_ALIGN_PARAGRAPH.CENTER)
            _data_cell(badge_tbl.rows[0].cells[2],
                       f"SWC: {f.get('swc_id','—')}",
                       bg="EAF0F8", align=WD_ALIGN_PARAGRAPH.CENTER)
            _data_cell(badge_tbl.rows[0].cells[3],
                       f"Location: {f.get('location','—')}",
                       bg="EAF0F8", align=WD_ALIGN_PARAGRAPH.CENTER)
            doc.add_paragraph()

            # Explanation
            if expl:
                ep = doc.add_paragraph()
                ep.paragraph_format.space_before = Pt(2)
                ep.paragraph_format.space_after  = Pt(6)
                er = ep.add_run(expl)
                er.font.name      = "Calibri"
                er.font.size      = Pt(10)
                er.font.color.rgb = RGBColor(0x2D, 0x37, 0x48)

            # Vulnerable code block
            if bad_code:
                _code_block(doc, "❌  Vulnerable code:",
                            bad_code,
                            RGBColor(0xC0, 0x39, 0x3B), "3B1F1F")

            # Fixed code block
            if good_code:
                _code_block(doc, "✅  Fixed code:",
                            good_code,
                            RGBColor(0x21, 0x7A, 0x3C), "1A2E1A")

            doc.add_paragraph()

        if guide_n == 0:
            doc.add_paragraph(
                "No detailed fix guides available for the findings in this report."
            )
        doc.add_paragraph()

    # ═══════════════════════════════════════════════════════════════════════
    #  SECTION 5 — GAS ESTIMATION
    # ═══════════════════════════════════════════════════════════════════════
    sec5 = 5 if findings else 4
    doc.add_heading(f"{sec5}.  Gas Estimation", level=1)
    _accent_rule()

    gas_val = gas_metrics.get("estimated_gas", "N/A")
    fn_gas  = gas_metrics.get("function_gas", {})

    if gas_val in ("N/A", "Error") and not fn_gas:
        gp = doc.add_paragraph(
            "Gas estimation unavailable (solc not installed or not applicable)."
        )
        gp.runs[0].font.color.rgb = RGBColor(0x71, 0x80, 0x96)
    else:
        if gas_val not in ("N/A", "Error"):
            p = doc.add_paragraph()
            r = p.add_run("Estimated gas (external calls): ")
            r.bold = True
            p.add_run(f"{gas_val:,}" if isinstance(gas_val, int) else str(gas_val))
        if fn_gas:
            g_tbl = doc.add_table(rows=1, cols=2)
            g_tbl.style = "Table Grid"
            _hdr_cell(g_tbl.rows[0].cells[0], "Function")
            _hdr_cell(g_tbl.rows[0].cells[1], "Gas")
            for i, (fn, gas) in enumerate(sorted(fn_gas.items(), key=lambda x: -x[1])):
                row = g_tbl.add_row()
                bg  = "FFFFFF" if i % 2 == 0 else "F4F7FB"
                _data_cell(row.cells[0], fn,  bg=bg)
                _data_cell(row.cells[1],
                           f"{gas:,}" if isinstance(gas, int) else str(gas),
                           bg=bg, align=WD_ALIGN_PARAGRAPH.RIGHT)
    doc.add_paragraph()

    # ═══════════════════════════════════════════════════════════════════════
    #  SECTION 6 — GENERAL RECOMMENDATIONS
    # ═══════════════════════════════════════════════════════════════════════
    sec6 = sec5 + 1
    doc.add_heading(f"{sec6}.  General Recommendations", level=1)
    _accent_rule()
    for rec in [
        "Perform a manual code review by experienced smart contract security auditors.",
        "Use OpenZeppelin libraries for standard components (access control, tokens, proxies).",
        "Run comprehensive fuzz testing with Echidna or Medusa before deployment.",
        "Apply formal verification with Halmos for critical invariants and state transitions.",
        "Deploy to a testnet with realistic conditions before mainnet launch.",
        "Subscribe to Solidity and EVM security advisories for ongoing awareness.",
        "Consider a bug bounty program post-deployment to catch production issues.",
    ]:
        p = doc.add_paragraph(style="List Bullet")
        r = p.add_run(rec)
        r.font.name = "Calibri"
        r.font.size = Pt(10.5)
    doc.add_paragraph()

    # ═══════════════════════════════════════════════════════════════════════
    #  SECTION 7 — DISCLAIMER
    # ═══════════════════════════════════════════════════════════════════════
    sec7 = sec6 + 1
    doc.add_heading(f"{sec7}.  Disclaimer", level=1)
    _accent_rule()
    d_tbl  = doc.add_table(rows=1, cols=1)
    d_tbl.style = "Table Grid"
    d_cell = d_tbl.rows[0].cells[0]
    _set_cell_bg(d_cell, "F4F7FB")
    _cell_margins(d_cell, 140, 140, 200, 200)
    d_tc   = d_cell._tc
    d_tcPr = d_tc.get_or_add_tcPr()
    for side in ("top", "left", "right", "bottom"):
        b = OxmlElement(f"w:{side}")
        b.set(qn("w:val"),   "single")
        b.set(qn("w:sz"),    "6")
        b.set(qn("w:color"), "00A8E8")
        d_tcPr.append(b)
    dp = d_cell.paragraphs[0]
    dr = dp.add_run(
        "This report was generated automatically by an automated analysis tool and does not "
        "substitute a professional manual audit by qualified security researchers. Results may "
        "include false positives and may not cover all possible attack vectors. Multiple "
        "independent verification methods are strongly recommended before any mainnet deployment."
    )
    dr.font.name      = "Calibri"
    dr.font.size      = Pt(9.5)
    dr.font.italic    = True
    dr.font.color.rgb = RGBColor(0x71, 0x80, 0x96)

    # ── Save ──────────────────────────────────────────────────────────────
    def _try_save_docx(path: str) -> bool:
        try:
            doc.save(path)
            _print(f"Word report (python-docx) saved: {path}", "green")
            logger.info("DOCX saved: %s", os.path.abspath(path))
            return True
        except PermissionError as pe:
            _print(f"Permission denied: {path} — {pe}", "yellow")
            logger.warning("DOCX permission denied: %s — %s", path, pe)
            return False
        except Exception as e:
            _print(f"Failed to save DOCX: {e}", "red")
            logger.error("DOCX save error: %s", e)
            return False

    if not _try_save_docx(output_filename):
        # Первый фолбэк: рядом со скриптом
        fallback1 = os.path.join(_SCRIPT_DIR, os.path.basename(output_filename))
        if fallback1 != output_filename and not _try_save_docx(fallback1):
            # Второй фолбэк: Desktop пользователя
            desktop = os.path.join(os.path.expanduser("~"), "Desktop", os.path.basename(output_filename))
            if not _try_save_docx(desktop):
                # Третий фолбэк: домашняя папка пользователя
                home = os.path.join(os.path.expanduser("~"), os.path.basename(output_filename))
                _try_save_docx(home)
        elif fallback1 == output_filename:
            # Уже пробовали этот путь, идём сразу на Desktop
            desktop = os.path.join(os.path.expanduser("~"), "Desktop", os.path.basename(output_filename))
            if not _try_save_docx(desktop):
                home = os.path.join(os.path.expanduser("~"), os.path.basename(output_filename))
                _try_save_docx(home)


# ─────────────────────────────────────────────────────────────────────────────
#  JSON REPORT
# ─────────────────────────────────────────────────────────────────────────────

def generate_json_report(findings: list[dict], contract_path: str, output_filename: str = JSON_OUTPUT) -> None:
    # Compute overall risk score = average CVSS of all findings (0–10)
    scores = [f.get("cvss_score", 0) for f in findings if isinstance(f.get("cvss_score"), float)]
    avg_cvss = round(sum(scores) / len(scores), 2) if scores else 0.0
    max_cvss = max(scores) if scores else 0.0

    report = {
        "contract":      os.path.basename(contract_path),
        "date":          datetime.now().isoformat(),
        "total":         len(findings),
        "risk_summary": {
            "average_cvss_score": avg_cvss,
            "max_cvss_score":     round(max_cvss, 1),
            "overall_risk_band":  cvss_severity_band(max_cvss),
        },
        "severities": {
            sev: sum(1 for f in findings if f["severity"] == sev)
            for sev in ["Critical", "High", "Medium", "Low", "Info"]
        },
        "findings": findings,
    }
    def _try_save_json(path: str) -> bool:
        try:
            with open(path, "w", encoding="utf-8") as fp:
                json.dump(report, fp, indent=2, ensure_ascii=False)
            _print(f"JSON report saved: {path}", "green")
            return True
        except PermissionError as pe:
            _print(f"Permission denied: {path} — {pe}", "yellow")
            return False
        except Exception as e:
            _print(f"Error saving JSON: {e}", "red")
            return False

    if not _try_save_json(output_filename):
        fallback1 = os.path.join(_SCRIPT_DIR, os.path.basename(output_filename))
        if fallback1 != output_filename and not _try_save_json(fallback1):
            desktop = os.path.join(os.path.expanduser("~"), "Desktop", os.path.basename(output_filename))
            if not _try_save_json(desktop):
                home = os.path.join(os.path.expanduser("~"), os.path.basename(output_filename))
                _try_save_json(home)
        elif fallback1 == output_filename:
            desktop = os.path.join(os.path.expanduser("~"), "Desktop", os.path.basename(output_filename))
            if not _try_save_json(desktop):
                home = os.path.join(os.path.expanduser("~"), os.path.basename(output_filename))
                _try_save_json(home)


# ─────────────────────────────────────────────────────────────────────────────
#  CLI & MAIN
# ─────────────────────────────────────────────────────────────────────────────

def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Solidity Smart Contract Security Auditor — v7000",
        formatter_class=argparse.RawTextHelpFormatter,
        epilog="""Examples:
  python AuditTOOL7000.py MyToken.sol                     # single file
  python AuditTOOL7000.py ./my-foundry-project            # Foundry project
  python AuditTOOL7000.py ./my-hardhat-project            # Hardhat project
  python AuditTOOL7000.py MyToken.sol --slither --doc     # selected tools
  python AuditTOOL7000.py                                 # interactive mode
""")
    parser.add_argument(
        "contract_path", nargs="?",
        help="Path to .sol file OR project directory (Foundry / Hardhat auto-detected)",
    )
    parser.add_argument("--check-tools", action="store_true", help="Show tool versions and exit")
    g = parser.add_argument_group("Analyzers")
    g.add_argument("--slither",  action="store_true")
    g.add_argument("--mythril",  action="store_true")
    g.add_argument("--echidna",  action="store_true")
    g.add_argument("--medusa",   action="store_true")
    g.add_argument("--halmos",   action="store_true")
    g.add_argument("--static",   action="store_true")
    g.add_argument("--all",      action="store_true", help="Run all analyzers (default if none selected)")
    p = parser.add_argument_group("Project type (override auto-detect)")
    p.add_argument("--foundry",  action="store_true", help="Force Foundry project mode")
    p.add_argument("--hardhat",  action="store_true", help="Force Hardhat project mode")
    r = parser.add_argument_group("Reports")
    r.add_argument("--doc",        action="store_true", help="Generate .docx report")
    r.add_argument("--json",       action="store_true", help="Generate .json report")
    r.add_argument("--doc-output",  default=DOC_OUTPUT, metavar="FILE")
    r.add_argument("--json-output", default=JSON_OUTPUT, metavar="FILE")
    return parser.parse_args()


def interactive_mode() -> tuple[str, str]:
    """Launch a local web UI so the user can upload a .sol file from the script directory."""
    _print("\nStarting local file upload interface...", "bold cyan")

    # Result container shared between threads
    result: dict = {"source": None, "filename": None, "done": False}

    # Determine the directory where the script lives — uploaded .sol files must be there
    script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))

    HTML_PAGE = """<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>AuditTOOL4000 – Upload Contract</title>
<style>
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body { font-family: 'Segoe UI', 'Inter', Arial, sans-serif; background: #0a0e17; color: #c9d1d9; min-height: 100vh; display: flex; align-items: center; justify-content: center; }
  .card { background: #13192a; border: 1px solid #1f2b40; border-radius: 14px; padding: 36px 44px; max-width: 500px; width: 100%; box-shadow: 0 12px 40px rgba(0,0,0,.6), 0 1px 0 rgba(255,255,255,.04) inset; }
  .brand { display: flex; align-items: center; gap: 10px; margin-bottom: 4px; }
  h1 { font-size: 1.45rem; font-weight: 700; color: #e6edf3; letter-spacing: -0.02em; }
  .badge { font-size: 0.68rem; font-weight: 600; background: #1b3d6b; color: #58a6ff; border-radius: 5px; padding: 2px 7px; letter-spacing: 0.05em; text-transform: uppercase; }
  .subtitle { color: #6e7b8f; font-size: 0.875rem; margin-bottom: 26px; line-height: 1.5; }
  .drop-zone { border: 1.5px dashed #263347; border-radius: 10px; padding: 32px 20px; text-align: center; cursor: pointer; transition: border-color .2s, background .2s; background: #0d1320; margin-bottom: 16px; }
  .drop-zone:hover, .drop-zone.drag-over { border-color: #3b82f6; background: #111d30; }
  .drop-icon { font-size: 2.2rem; margin-bottom: 10px; line-height: 1; }
  .drop-text { color: #6e7b8f; font-size: 0.875rem; line-height: 1.6; }
  .drop-text strong { color: #b0bac6; font-weight: 600; }
  #fileInput { display: none; }
  .file-info { background: #1a2234; border-radius: 8px; padding: 11px 15px; margin-bottom: 16px; display: none; align-items: center; gap: 10px; border: 1px solid #1f2b40; }
  .file-icon { font-size: 1.3rem; flex-shrink: 0; }
  .file-name { color: #58a6ff; font-weight: 600; font-size: 0.9rem; word-break: break-all; }
  .file-size { color: #6e7b8f; font-size: 0.78rem; margin-top: 1px; }
  .btn { display: block; width: 100%; padding: 11px; font-size: 0.95rem; font-weight: 600; border: none; border-radius: 9px; cursor: pointer; transition: opacity .15s, box-shadow .15s; letter-spacing: 0.01em; }
  .btn-primary { background: linear-gradient(135deg, #1a6b39, #22863a); color: #fff; box-shadow: 0 2px 8px rgba(34,134,58,.3); }
  .btn-primary:hover { opacity: .9; box-shadow: 0 4px 14px rgba(34,134,58,.4); }
  .btn-primary:disabled { background: #1c2333; color: #4d5666; cursor: not-allowed; opacity: 1; box-shadow: none; }
  .status { margin-top: 14px; text-align: center; font-size: 0.875rem; color: #6e7b8f; min-height: 20px; line-height: 1.5; }
  .status.ok  { color: #3fb950; }
  .status.err { color: #f85149; }
  .note { margin-top: 18px; background: #111d2e; border-left: 2.5px solid #1f6feb; border-radius: 6px; padding: 10px 14px; font-size: 0.81rem; color: #6e7b8f; line-height: 1.6; }
  .note code { background: #1a2234; border-radius: 3px; padding: 1px 5px; font-size: 0.79rem; color: #79c0ff; font-family: 'Cascadia Code', 'Consolas', monospace; }
</style>
</head>
<body>
<div class="card">
  <div class="brand">
    <h1>🔍 AuditTOOL</h1>
    <span class="badge">v7000</span>
  </div>
  <p class="subtitle">Solidity Smart Contract Security Auditor</p>

  <div class="drop-zone" id="dropZone" onclick="document.getElementById('fileInput').click()">
    <div class="drop-icon">📄</div>
    <div class="drop-text"><strong>Click to select</strong> or drag &amp; drop a <code>.sol</code> file</div>
    <input type="file" id="fileInput" accept=".sol"/>
  </div>

  <div class="file-info" id="fileInfo">
    <span class="file-icon">📝</span>
    <div>
      <div class="file-name" id="fileName"></div>
      <div class="file-size" id="fileSize"></div>
    </div>
  </div>

  <button class="btn btn-primary" id="analyzeBtn" disabled onclick="uploadFile()">
    ▶ Start Analysis
  </button>

  <div class="status" id="status"></div>

  <div class="note">
    ℹ️ The <code>.sol</code> file must reside in the <strong>same directory</strong> as the script.<br>
    This page will close automatically once the analysis begins.
  </div>
</div>

<script>
  let selectedFile = null;

  const dropZone   = document.getElementById('dropZone');
  const fileInput  = document.getElementById('fileInput');
  const fileInfo   = document.getElementById('fileInfo');
  const fileName   = document.getElementById('fileName');
  const fileSize   = document.getElementById('fileSize');
  const analyzeBtn = document.getElementById('analyzeBtn');
  const statusEl   = document.getElementById('status');

  function setFile(file) {
    if (!file) return;
    if (!file.name.endsWith('.sol')) {
      showStatus('Only .sol files are accepted.', 'err');
      return;
    }
    selectedFile = file;
    fileName.textContent = file.name;
    fileSize.textContent = (file.size / 1024).toFixed(1) + ' KB';
    fileInfo.style.display = 'flex';
    analyzeBtn.disabled = false;
    showStatus('');
  }

  fileInput.addEventListener('change', () => setFile(fileInput.files[0]));

  dropZone.addEventListener('dragover', e => { e.preventDefault(); dropZone.classList.add('drag-over'); });
  dropZone.addEventListener('dragleave', () => dropZone.classList.remove('drag-over'));
  dropZone.addEventListener('drop', e => {
    e.preventDefault();
    dropZone.classList.remove('drag-over');
    setFile(e.dataTransfer.files[0]);
  });

  function showStatus(msg, cls) {
    statusEl.textContent = msg;
    statusEl.className = 'status' + (cls ? ' ' + cls : '');
  }

  function uploadFile() {
    if (!selectedFile) return;
    analyzeBtn.disabled = true;
    showStatus('Uploading and starting analysis…');

    const reader = new FileReader();
    reader.onload = function(ev) {
      fetch('/upload', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ filename: selectedFile.name, content: ev.target.result })
      })
      .then(r => r.json())
      .then(data => {
        if (data.ok) {
          showStatus('✅ Analysis started! Check the terminal for results. This tab will close.', 'ok');
          setTimeout(() => window.close(), 2500);
        } else {
          showStatus('Error: ' + data.error, 'err');
          analyzeBtn.disabled = false;
        }
      })
      .catch(err => {
        showStatus('Upload failed: ' + err, 'err');
        analyzeBtn.disabled = false;
      });
    };
    reader.readAsText(selectedFile);
  }
</script>
</body>
</html>"""

    class _Handler(http.server.BaseHTTPRequestHandler):
        def log_message(self, fmt, *args):
            pass  # Suppress default HTTP log spam

        def do_GET(self):
            body = HTML_PAGE.encode("utf-8")
            self.send_response(200)
            self.send_header("Content-Type", "text/html; charset=utf-8")
            self.send_header("Content-Length", str(len(body)))
            self.end_headers()
            self.wfile.write(body)

        def do_POST(self):
            if self.path != "/upload":
                self.send_response(404)
                self.end_headers()
                return
            length = int(self.headers.get("Content-Length", 0))
            raw = self.rfile.read(length)
            try:
                payload = json.loads(raw)
                filename = payload.get("filename", "").strip()
                content  = payload.get("content", "")

                if not filename.endswith(".sol"):
                    raise ValueError("Only .sol files are accepted.")
                if not content:
                    raise ValueError("Empty file content.")

                # PATH TRAVERSAL PROTECTION: ensure the resolved path stays
                # inside the script directory (prevents ../../../etc/passwd attacks)
                sol_path     = os.path.realpath(os.path.join(script_dir, filename))
                safe_root    = os.path.realpath(script_dir)
                if not sol_path.startswith(safe_root + os.sep) and sol_path != safe_root:
                    raise ValueError("Invalid filename: path traversal detected.")

                # Verify the file exists in the script directory
                if not os.path.isfile(sol_path):
                    raise FileNotFoundError(
                        f"'{filename}' was not found in the script directory:\n{script_dir}\n"
                        "Please ensure the .sol file is in the same folder as the script."
                    )

                result["source"]   = content
                result["filename"] = sol_path
                result["done"]     = True

                resp = json.dumps({"ok": True}).encode()
                self.send_response(200)
                self.send_header("Content-Type", "application/json")
                self.send_header("Content-Length", str(len(resp)))
                self.end_headers()
                self.wfile.write(resp)

            except Exception as exc:
                resp = json.dumps({"ok": False, "error": str(exc)}).encode()
                self.send_response(400)
                self.send_header("Content-Type", "application/json")
                self.send_header("Content-Length", str(len(resp)))
                self.end_headers()
                self.wfile.write(resp)

    # Find a free port starting at 8765
    port = 8765
    for _ in range(20):
        try:
            server = http.server.HTTPServer(("127.0.0.1", port), _Handler)
            break
        except OSError:
            port += 1
    else:
        _print("Could not find a free port for the upload UI.", "red")
        sys.exit(1)

    def _serve():
        while not result["done"]:
            server.handle_request()
        server.server_close()

    srv_thread = threading.Thread(target=_serve, daemon=True)
    srv_thread.start()

    url = f"http://127.0.0.1:{port}/"
    _print(f"Upload interface running at: {url}", "bold green")
    _print("Opening browser… (close this tab after analysis starts)", "dim")
    webbrowser.open(url)

    # Wait for the user to upload a file
    try:
        while not result["done"]:
            time.sleep(0.1)
    except KeyboardInterrupt:
        _print("\nUpload cancelled.", "yellow")
        sys.exit(0)

    srv_thread.join(timeout=3)

    source   = result["source"]
    sol_path = result["filename"]

    if not source:
        _print("No file content received.", "red")
        sys.exit(1)

    _print(f"File received: {os.path.basename(sol_path)}", "bold green")
    return source, sol_path


def main() -> None:
    args = parse_args()

    if args.check_tools:
        auto_update_tools()
        sys.exit(0)
    else:
        auto_update_tools()

    # ── Determine input path ──────────────────────────────────────────────────
    if args.contract_path:
        input_path = args.contract_path
    else:
        _source, input_path = interactive_mode()

    # ── Project detection ─────────────────────────────────────────────────────
    if args.foundry:
        project_type = ProjectType.FOUNDRY
        project_root = os.path.abspath(input_path) if os.path.isdir(input_path) else os.path.dirname(os.path.abspath(input_path))
    elif args.hardhat:
        project_type = ProjectType.HARDHAT
        project_root = os.path.abspath(input_path) if os.path.isdir(input_path) else os.path.dirname(os.path.abspath(input_path))
    else:
        project_type, project_root = detect_project(input_path)

    sol_files, main_path = _collect_sol_sources(project_root, project_type)
    source = _read_combined_source(sol_files)

    # Display what we found
    type_label = {
        ProjectType.SINGLE_FILE: "Single file",
        ProjectType.FOUNDRY:     "Foundry project",
        ProjectType.HARDHAT:     "Hardhat project",
    }.get(project_type, project_type)

    _print(f"\n{'─'*60}", "dim")
    _print(f"  Mode      : {type_label}", "bold cyan")
    _print(f"  Root      : {project_root}", "cyan")
    _print(f"  .sol files: {len(sol_files)}", "cyan")
    _print(f"{'─'*60}\n", "dim")

    t0 = time.monotonic()

    # ── Build task list ───────────────────────────────────────────────────────
    explicit = any([args.slither, args.mythril, args.echidna,
                    args.medusa, args.halmos, args.static])
    run_all  = args.all or not explicit

    tasks: dict[str, callable] = {}

    # Project-level tasks (Foundry / Hardhat) run on project root
    if project_type == ProjectType.FOUNDRY:
        tasks["ForgeBuild"] = lambda: run_foundry_build(project_root)
        tasks["ForgeTest"]  = lambda: run_foundry_tests(project_root)
    elif project_type == ProjectType.HARDHAT:
        tasks["HHCompile"]  = lambda: run_hardhat_compile(project_root)
        tasks["HHTest"]     = lambda: run_hardhat_tests(project_root)

    # Security analyzers — pass project_root for projects, main_path for single file
    analyze_target = project_root if project_type != ProjectType.SINGLE_FILE else main_path

    if run_all or args.slither:  tasks["Slither"] = lambda: run_slither(analyze_target)
    if run_all or args.mythril:  tasks["Mythril"] = lambda: run_mythril(analyze_target)
    if run_all or args.echidna:  tasks["Echidna"] = lambda: run_echidna(analyze_target)
    if run_all or args.medusa:   tasks["Medusa"]  = lambda: run_medusa(analyze_target)
    if run_all or args.halmos:   tasks["Halmos"]  = lambda: run_halmos(analyze_target)
    if run_all or args.static:   tasks["Static"]  = lambda: run_static_analysis(source, main_path)
    tasks["AST"] = lambda: run_ast_analysis(main_path, source)

    # ── Parallel execution ────────────────────────────────────────────────────
    _print(
        f"Launching {len(tasks)} task(s) in parallel "
        f"(max_workers={min(len(tasks), 6)})...",
        "bold cyan",
    )
    findings: list[dict] = []
    coverage_metrics: dict = {}

    # Run forge coverage separately (not security, just metrics)
    if project_type == ProjectType.FOUNDRY and shutil.which("forge"):
        cov_future_tasks = {"ForgeCoverage": lambda: run_foundry_coverage(project_root)}
        tasks.update(cov_future_tasks)

    with ThreadPoolExecutor(max_workers=min(len(tasks), 6)) as executor:
        future_to_name = {executor.submit(fn): name for name, fn in tasks.items()}
        for future in as_completed(future_to_name):
            name = future_to_name[future]
            try:
                result = future.result()
                if name == "ForgeCoverage":
                    if isinstance(result, dict):
                        coverage_metrics = result
                else:
                    if isinstance(result, list):
                        findings += result
            except Exception as exc:
                _print(f"[{name}] raised an exception: {exc}", "red")
                logger.warning("Analyzer %s raised: %s", name, exc)

    gas_metrics = estimate_gas(main_path, source)
    # Attach coverage to gas_metrics for display
    if coverage_metrics:
        gas_metrics["coverage"] = coverage_metrics

    findings = deduplicate(findings)
    findings = enrich_with_cvss(findings)

    elapsed = time.monotonic() - t0
    _print(f"\nAnalysis complete in {elapsed:.1f}s. Findings: {len(findings)}", "bold")

    print_console_report(findings, main_path, gas_metrics)

    generate_doc  = args.doc
    generate_json = args.json

    if not generate_doc and not generate_json:
        try:
            generate_doc  = input("\nSave .docx report? [Y/n]: ").strip().lower() in ("", "y")
            generate_json = input("Save .json report? [y/N]: ").strip().lower() == "y"
        except (EOFError, KeyboardInterrupt):
            pass

    if generate_doc:
        generate_docx_report(findings, main_path, gas_metrics, args.doc_output)
    if generate_json:
        generate_json_report(findings, main_path, args.json_output)

    critical_high = sum(1 for f in findings if f.get("severity") in ("Critical", "High"))
    sys.exit(2 if critical_high > 0 else 0)


if __name__ == "__main__":
    main()
//main crypto script
